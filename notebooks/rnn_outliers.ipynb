{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers and Missing Data (Processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 주요 패키지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from metr.components import Metadata, TrafficData\n",
    "from metr.components.metr_imc.interpolation import (\n",
    "    Interpolator,\n",
    "    LinearInterpolator,\n",
    "    MonthlyMeanFillInterpolator,\n",
    "    ShiftFillInterpolator,\n",
    "    SplineLinearInterpolator,\n",
    "    TimeMeanFillInterpolator,\n",
    ")\n",
    "from metr.components.metr_imc.outlier import (\n",
    "    HourlyInSensorZscoreOutlierProcessor,\n",
    "    InSensorZscoreOutlierProcessor,\n",
    "    MADOutlierProcessor,\n",
    "    OutlierProcessor,\n",
    "    TrimmedMeanOutlierProcessor,\n",
    "    WinsorizedOutlierProcessor,\n",
    ")\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error\n",
    "from songdo_rnn.preprocessing.missing import interpolate\n",
    "from songdo_rnn.preprocessing.outlier import remove_outliers\n",
    "from tqdm import tqdm\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"AppleGothic\"\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False  # 음수 부호 깨짐 방지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 공통 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_list(data_dir: str) -> List[TrafficData]:\n",
    "    data_path_list = glob(os.path.join(data_dir, \"*.h5\"))\n",
    "    return [TrafficData.import_from_hdf(path) for path in data_path_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 데이터 비교\n",
    "def visualize_df_comparison(\n",
    "    df1: pd.Series,\n",
    "    df2: pd.Series,\n",
    "    title: str = \"\",\n",
    "    df1_attr: Dict[str, str] = {\"label\": \"Source\", \"color\": \"red\"},\n",
    "    df2_attr: Dict[str, str] = {\"label\": \"Target\", \"color\": \"blue\"},\n",
    "):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    df1.plot(**df1_attr)\n",
    "    df2.plot(**df2_attr)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 데이터 비교\n",
    "def vis_df_comparison_line_scatter(\n",
    "    df1: pd.Series,\n",
    "    df2: pd.Series,\n",
    "    title: str = \"\",\n",
    "    df1_attr: Dict[str, str] = {\"label\": \"Source\", \"color\": \"blue\"},\n",
    "    df2_attr: Dict[str, str] = {\"label\": \"Target\", \"color\": \"red\", \"s\": 20},\n",
    "):\n",
    "    fig, ax = plt.subplots(figsize=(12, 5))\n",
    "    sns.lineplot(data=df1, ax=ax, **df1_attr)\n",
    "    sns.scatterplot(data=df2, ax=ax, **df2_attr)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_df_comparison_scatter(\n",
    "    df1: pd.Series,\n",
    "    df2: pd.Series,\n",
    "    title: str = \"\",\n",
    "    df1_attr: Dict[str, str] = {\"label\": \"Source\", \"color\": \"red\", \"s\": 10},\n",
    "    df2_attr: Dict[str, str] = {\"label\": \"Target\", \"color\": \"blue\", \"s\": 10},\n",
    "):\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    sns.scatterplot(data=df1, ax=ax, **df1_attr)\n",
    "    sns.scatterplot(data=df2, ax=ax, **df2_attr)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTLIER_DATA_DIR = \"./output/outlier_processed\"\n",
    "OUTLIER_STEST_DATA_DIR = os.path.join(OUTLIER_DATA_DIR, \"stest\")\n",
    "OUTLIER_PTEST_DATA_DIR = os.path.join(OUTLIER_DATA_DIR, \"ptest\")\n",
    "INTERPOLATED_DATA_DIR = \"./output/interpolated\"\n",
    "INTERPOLATED_STEST_DATA_DIR = os.path.join(INTERPOLATED_DATA_DIR, \"stest\")\n",
    "INTERPOLATED_PTEST_DATA_DIR = os.path.join(INTERPOLATED_DATA_DIR, \"ptest\")\n",
    "PREDICTION_OUTPUT_DIR = \"./output/prediction\"\n",
    "\n",
    "RAW_DATA_PATH = \"../datasets/metr-imc/metr-imc.h5\"\n",
    "BASE_DATA_PATH = \"./output/outlier_processed/base.h5\"\n",
    "\n",
    "os.makedirs(OUTLIER_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(OUTLIER_STEST_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(OUTLIER_PTEST_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(INTERPOLATED_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(INTERPOLATED_STEST_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(INTERPOLATED_PTEST_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(PREDICTION_OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "raw_data = TrafficData.import_from_hdf(RAW_DATA_PATH)\n",
    "base_data = TrafficData.import_from_hdf(BASE_DATA_PATH)\n",
    "raw_df = raw_data.data\n",
    "base_df = base_data.data\n",
    "base_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Test Data Split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_start = pd.Timestamp(\"2024-08-01\")\n",
    "test_end = pd.Timestamp(\"2024-08-01\")\n",
    "\n",
    "ratio = 0.25\n",
    "for i in range(8, 12):\n",
    "    test_start = pd.Timestamp(f\"2024-{i:02d}-01\")\n",
    "    test_end = pd.Timestamp(f\"2024-{i + 1:02d}-01\")\n",
    "\n",
    "    test_cand = raw_df.loc[test_start:test_end]\n",
    "    test_cand_no_na = test_cand.dropna(axis=1)\n",
    "    print(test_start, \"-\", test_end, \":\", test_cand_no_na.shape[1], \"/\", test_cand.shape[1])\n",
    "\n",
    "    train_data = raw_df.loc[(raw_df.index < test_start) | (raw_df.index >= test_end)]\n",
    "    na_ratio = train_data.isna().mean()\n",
    "    sensors_less_than = (na_ratio <= ratio).sum()\n",
    "    total_sensors = train_data.shape[1]\n",
    "    print(f\"테스트 기간 외 결측치 비율 {ratio} 이하 센서: {sensors_less_than} / {total_sensors} ({sensors_less_than/total_sensors:.2%})\")\n",
    "\n",
    "# 적당히 길면서 결측치가 많지 않은 2024-10-01 ~ 2024-10-30 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df: pd.DataFrame = raw_df.loc[:\"2024-09-30\"]\n",
    "test_df: pd.DataFrame = raw_df.loc[\"2024-10-01\":\"2024-10-31\"]\n",
    "\n",
    "print(\"Training Length:\", training_df.index.min(), \"-\", training_df.index.max())\n",
    "print(\"Test Length:\", test_df.index.min(), \"-\", test_df.index.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스트 데이터에는 결측치가 있으면 안 되므로 현 연구에 사용되는 데이터는 결측치가 없는 데이터로 선택."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_no_na = test_df.dropna(axis=1)\n",
    "\n",
    "test_df = test_data_no_na\n",
    "training_df = training_df[test_df.columns]\n",
    "\n",
    "print(\"Test Data Shape: From\", test_df.shape, \"to\", test_data_no_na.shape)\n",
    "print(\"Training Data Shape: From\", training_df.shape, \"to\", training_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트 데이터 임의 결측치 생성\n",
    "\n",
    "이상치는 z-score 3이상을 이상치로 판단하고 Training 데이터에서 그 분포를 추출한다. 그리고 Training 데이터 비율과 동일하게 Test 데이터에 이상치와 결측치를 추가한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이상치 분포 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터에 NaN이 없는지 다시 확인\n",
    "test_df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이상치 데이터의 범위\n",
    "t_all = training_df.values.flatten()\n",
    "t_all = t_all[~np.isnan(t_all)]\n",
    "t_mean = t_all.mean()\n",
    "t_std = t_all.std()\n",
    "t_z = (t_all - t_mean) / t_std\n",
    "t_outlier_indices = np.where(np.abs(t_z) > 3)[0]\n",
    "t_outliers = t_all[t_outlier_indices]\n",
    "\n",
    "# 이상치 데이터의 범위와 통계 출력\n",
    "if len(t_outliers) > 0:\n",
    "    min_outlier = t_outliers.min()\n",
    "    max_outlier = t_outliers.max()\n",
    "    print(f\"이상치 데이터의 개수: {len(t_outliers)}\")\n",
    "    print(f\"이상치 데이터의 범위: {min_outlier:.2f}에서 {max_outlier:.2f}\")\n",
    "    print(f\"전체 데이터의 평균: {t_mean:.2f}, 표준편차: {t_std:.2f}\")\n",
    "    print(\n",
    "        f\"전체 데이터의 정상 범위: {t_mean - 3 * t_std:.2f}에서 {t_mean + 3 * t_std:.2f}\"\n",
    "    )\n",
    "    print(f\"이상치 비율: {len(t_outliers) / len(t_all) * 100:.2f}%\")\n",
    "else:\n",
    "    print(\"z-score가 3 이상인 이상치 데이터가 없습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 결측치 비율\n",
    "missing_ratio = training_df.isna().sum().sum() / training_df.size\n",
    "print(f\"전체 결측치 비율: {missing_ratio:.4f} ({missing_ratio*100:.2f}%)\")\n",
    "\n",
    "# 열별 결측치 비율\n",
    "column_missing = training_df.isna().mean()\n",
    "\n",
    "# 결측치가 가장 많은 열 확인\n",
    "print(\"\\n결측치가 가장 많은 열 Top 5:\")\n",
    "print(column_missing.sort_values(ascending=False).head())\n",
    "\n",
    "# 행별 결측치 비율 분포 확인\n",
    "row_missing = training_df.isna().mean(axis=1)\n",
    "print(f\"\\n행별 결측치 비율 평균: {row_missing.mean():.4f}\")\n",
    "print(f\"행별 결측치 비율 최댓값: {row_missing.max():.4f}\")\n",
    "\n",
    "# 결측치 값 출력\n",
    "t_outliers.sort()\n",
    "t_outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이상치 및 결측치 삽입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_test_df = test_df.copy()\n",
    "outlier_ratio = len(t_outliers) / len(t_all)\n",
    "missing_ratio = training_df.isna().sum().sum() / training_df.size\n",
    "total_points = corrupted_test_df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"원래 결측치:\", corrupted_test_df.isna().sum().sum())\n",
    "print(corrupted_test_df.shape)\n",
    "n_missing_in_sensor = test_df.shape[0] * missing_ratio  # 각 센서마다 결측치 개수\n",
    "corrupted_test_df = test_df.copy()\n",
    "\n",
    "failed_dict = {}\n",
    "for col_idx, col in enumerate(test_df.columns):\n",
    "    n_missing = int(n_missing_in_sensor)\n",
    "    \n",
    "    # 다양한 길이의 결측치 블록 생성\n",
    "    missing_lengths = []\n",
    "    while sum(missing_lengths) < n_missing:\n",
    "        remaining = n_missing - sum(missing_lengths)\n",
    "        length = np.random.randint(1, min(remaining + 1, n_missing + 1))\n",
    "        missing_lengths.append(length)\n",
    "    missing_lengths[-1] -= sum(missing_lengths) - n_missing\n",
    "    \n",
    "    # 현재 컬럼에서 사용 가능한 모든 행 인덱스\n",
    "    available_rows = set(range(test_df.shape[0]))\n",
    "    \n",
    "    # 각 결측치 블록 삽입\n",
    "    for length in missing_lengths:\n",
    "        max_attempts = 100  # 최대 시도 횟수 설정\n",
    "        attempt = 0\n",
    "        block_created = False\n",
    "        \n",
    "        while attempt < max_attempts and not block_created:\n",
    "            if len(available_rows) == 0 or length > len(available_rows):\n",
    "                print(f\"센서 {col}에 충분한 공간이 없습니다. 필요: {length}, 가용: {len(available_rows)}\")\n",
    "                break\n",
    "            \n",
    "            # 시작점 후보들 찾기\n",
    "            potential_starts = []\n",
    "            for row in available_rows:\n",
    "                # 현재 위치부터 length만큼의 연속된 인덱스가 모두 available_rows에 있는지 확인\n",
    "                if all((row + i) in available_rows for i in range(length)):\n",
    "                    potential_starts.append(row)\n",
    "            \n",
    "            if not potential_starts:\n",
    "                # 연속된 블록을 찾지 못했다면 더 짧은 블록으로 시도\n",
    "                if length > 1:\n",
    "                    length -= 1\n",
    "                    failed_dict[col] = (length, attempt)\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"센서 {col}에서 연속된 블록을 생성할 수 없습니다.\")\n",
    "                    break\n",
    "            \n",
    "            # 후보 중에서 무작위로 시작점 선택\n",
    "            start_row = np.random.choice(potential_starts)\n",
    "            for i in range(length):\n",
    "                row = start_row + i\n",
    "                corrupted_test_df.iloc[row, col_idx] = np.nan\n",
    "                available_rows.remove(row)\n",
    "            \n",
    "            block_created = True\n",
    "            \n",
    "        if not block_created:\n",
    "            print(f\"센서 {col}에서 {length} 길이의 블록 생성 실패\")\n",
    "\n",
    "actual_missing = corrupted_test_df.isna().sum().sum()\n",
    "expected_missing = int(n_missing_in_sensor * len(test_df.columns))\n",
    "print(f\"생성된 결측치 개수: {actual_missing}, 예상 결측치 개수: {expected_missing}\")\n",
    "print(failed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_outliers = int(total_points * outlier_ratio)  # 비율에 따른 이상치 개수\n",
    "\n",
    "#--------------------------------------------------------------------------\n",
    "\n",
    "# 결측치(NaN) 위치 찾기\n",
    "nan_mask = corrupted_test_df.isna().to_numpy()\n",
    "nan_indices = np.where(nan_mask.flatten())[0]  # 1차원 배열에서 NaN 위치 인덱스\n",
    "\n",
    "# 모든 가능한 인덱스에서 결측치 위치를 제외하고 유효한 인덱스만 선택\n",
    "all_indices = np.arange(total_points)\n",
    "valid_indices = np.setdiff1d(all_indices, nan_indices)\n",
    "\n",
    "# 유효한 인덱스 중에서 이상치 개수만큼 무작위 선택\n",
    "if len(valid_indices) < n_outliers:\n",
    "    print(f\"경고: 충분한 유효 위치가 없습니다. 필요: {n_outliers}, 가용: {len(valid_indices)}\")\n",
    "    n_outliers = len(valid_indices)\n",
    "\n",
    "#--------------------------------------------------------------------------\n",
    "\n",
    "random_indices = np.random.choice(total_points, n_outliers, replace=False)\n",
    "rows = random_indices // corrupted_test_df.shape[1]\n",
    "cols = random_indices % corrupted_test_df.shape[1]\n",
    "\n",
    "# 선택된 인덱스에 이상치 데이터 삽입\n",
    "for i in range(n_outliers):\n",
    "    # t_outliers에서 랜덤하게 하나 선택\n",
    "    outlier_value = np.random.choice(t_outliers)\n",
    "    r, c = rows[i], cols[i]\n",
    "    corrupted_test_df.iloc[r, c] = outlier_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"원본 test_df 크기: {test_df.shape}\")\n",
    "print(f\"손상된 test_df 크기: {corrupted_test_df.shape}\")\n",
    "print(f\"추가된 이상치 개수: {n_outliers} (비율: {outlier_ratio:.4f})\")\n",
    "print(f\"추가된 결측치 개수: {n_missing} (비율: {missing_ratio:.4f})\")\n",
    "print(f\"손상된 데이터의 실제 결측치 비율: {corrupted_test_df.isna().sum().sum() / corrupted_test_df.size:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최종 데이터 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결측치 및 이상치 대체를 위한 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srep_df = pd.concat([training_df, corrupted_test_df], axis=0, copy=True)\n",
    "print(srep_df.shape)\n",
    "print(srep_df.index.is_monotonic_increasing)\n",
    "srep_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예측 모델 테스트를 위한 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_hdf(os.path.join(PREDICTION_OUTPUT_DIR, \"test.h5\"), key=\"data\")\n",
    "print(\"테스트 데이터 저장 완료 여부:\")\n",
    "os.path.exists(os.path.join(PREDICTION_OUTPUT_DIR, \"test.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_processors: List[OutlierProcessor] = [\n",
    "    HourlyInSensorZscoreOutlierProcessor(),\n",
    "    InSensorZscoreOutlierProcessor(),\n",
    "    WinsorizedOutlierProcessor(),\n",
    "    TrimmedMeanOutlierProcessor(),\n",
    "    MADOutlierProcessor(),\n",
    "]\n",
    "\n",
    "base_name = \"base_alt\"\n",
    "outlier_processors[0].name = \"hzscore\"\n",
    "outlier_processors[1].name = \"zscore\"\n",
    "outlier_processors[2].name = \"winsor\"\n",
    "outlier_processors[3].name = \"trimm\"\n",
    "outlier_processors[4].name = \"mad\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단순 보정 성능 측정용 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srep_df.to_hdf(os.path.join(OUTLIER_STEST_DATA_DIR, f\"{base_name}.h5\"), key=\"data\")\n",
    "\n",
    "srep_outlier_result_paths = remove_outliers(\n",
    "    data=srep_df,\n",
    "    outlier_processors=outlier_processors,\n",
    "    output_dir=OUTLIER_STEST_DATA_DIR,\n",
    ")\n",
    "srep_outlier_result_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srep_outlier_results = get_data_list(OUTLIER_STEST_DATA_DIR)\n",
    "srep_outlier_dfs = [tdata.data for tdata in srep_outlier_results]\n",
    "len(srep_outlier_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예측 모델용 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df.to_hdf(os.path.join(OUTLIER_PTEST_DATA_DIR, f\"{base_name}.h5\"), key=\"data\")\n",
    "\n",
    "pred_outlier_result_paths = remove_outliers(\n",
    "    data=training_df,\n",
    "    outlier_processors=outlier_processors,\n",
    "    output_dir=OUTLIER_PTEST_DATA_DIR,\n",
    ")\n",
    "pred_outlier_result_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_outlier_results = get_data_list(OUTLIER_PTEST_DATA_DIR)\n",
    "pred_outlier_dfs = [tdata.data for tdata in pred_outlier_results]\n",
    "len(pred_outlier_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier 처리 결과 확인 및 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = -1\n",
    "outlier_type = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df = srep_outlier_dfs[outlier_type]\n",
    "while idx < target_df.shape[1] - 1:\n",
    "    idx += 1\n",
    "    target = target_df.iloc[:, idx]\n",
    "    source = raw_df[target.name]\n",
    "    source = source.loc[target.index.min():target.index.max()]\n",
    "    \n",
    "\n",
    "    if source.isna().sum() == target.isna().sum():\n",
    "        # 결측치 처리가 되지 않은 경우는 제외\n",
    "        continue\n",
    "\n",
    "    visualize_df_comparison(source, target, title=f\"Source vs Target: {source.name}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 0.75\n",
    "target_df_idx = 2\n",
    "\n",
    "too_many_missing_sensors = set()\n",
    "\n",
    "df = None\n",
    "target_df = None\n",
    "for idx, data in enumerate(pred_outlier_results):\n",
    "    df = data.data\n",
    "    na_ratio = df.isna().mean()\n",
    "    sensors_less_than_list = na_ratio <= ratio\n",
    "    too_many_na_sensors = sensors_less_than_list[~sensors_less_than_list].index\n",
    "\n",
    "    if idx == target_df_idx:\n",
    "        target_df = df[too_many_na_sensors]\n",
    "\n",
    "    sensors_less_than = sensors_less_than_list.sum()\n",
    "    total_sensors = df.shape[1]\n",
    "    print(\n",
    "        f\"{data.path} 결측치 비율 {ratio} 이하 센서: {sensors_less_than} / {total_sensors} ({sensors_less_than/total_sensors:.2%})\"\n",
    "    )\n",
    "    print(\", \".join(too_many_na_sensors[:5]), \"...\", f\"{len(too_many_na_sensors)}개\")\n",
    "\n",
    "    too_many_missing_sensors.update(too_many_na_sensors)\n",
    "\n",
    "len(too_many_missing_sensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 제대로 보간되지 않을 것으로 예상되는 데이터\n",
    "\n",
    "Outlier 제거된 데이터에서 결측치가 너무 많이 관찰되는 센서 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_a = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while idx_a < target_df.shape[1] - 1:\n",
    "    idx_a += 1\n",
    "    target = target_df.iloc[:, idx_a]\n",
    "    source = raw_df[target.name]\n",
    "    source = source.loc[target.index.min() : target.index.max()]\n",
    "\n",
    "    if source.isna().sum() == target.isna().sum():\n",
    "        # 결측치 처리가 되지 않은 경우는 제외\n",
    "        continue\n",
    "\n",
    "    print(idx_a)\n",
    "    visualize_df_comparison(source, target, title=f\"Source vs Target: {source.name}\")\n",
    "    break\n",
    "else:\n",
    "    print(\"모든 센서에 대해 비교 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결측치 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolators: List[Interpolator] = [\n",
    "    LinearInterpolator(),\n",
    "    SplineLinearInterpolator(),\n",
    "    TimeMeanFillInterpolator(),\n",
    "    MonthlyMeanFillInterpolator(),\n",
    "    ShiftFillInterpolator(periods=7 * 24),\n",
    "]\n",
    "\n",
    "interpolators[0].name = \"linear\"\n",
    "interpolators[1].name = \"spline\"\n",
    "interpolators[2].name = \"time_mean\"\n",
    "interpolators[3].name = \"monthly_mean\"\n",
    "interpolators[4].name = \"week_shift\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_nans(data: pd.Series, idx: int, resample: str = \"3d\"):\n",
    "    target_s_na = pd.Series(index=data.index)\n",
    "    target_s_na[data.isna()] = 0\n",
    "    # print(target_s_na.loc[target_s_na == 0])\n",
    "\n",
    "    target_gs = pd.Series(index=data.index)\n",
    "    target_resampled = data.resample(\"3d\").mean()\n",
    "    target_gs.loc[target_resampled.index] = target_resampled\n",
    "\n",
    "    vis_df_comparison_line_scatter(target_gs, target_s_na)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단순 보정 성능 측정용 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srep_result_paths = interpolate(srep_outlier_results, interpolators, INTERPOLATED_STEST_DATA_DIR)\n",
    "len(srep_result_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srep_results = get_data_list(INTERPOLATED_STEST_DATA_DIR)\n",
    "srep_dfs = [tdata.data for tdata in srep_results]\n",
    "len(srep_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 보간되지 못한 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in srep_results:\n",
    "    # 각 열의 결측치 개수를 먼저 계산\n",
    "    na_counts_per_col = data.data.isna().sum()\n",
    "    cols_with_missings = (na_counts_per_col > 0).sum()\n",
    "    total_cols = data.data.shape[1]\n",
    "    missing_ratio = cols_with_missings / total_cols * 100\n",
    "    \n",
    "    print(f\"{data.path}: 결측치가 있는 열 {cols_with_missings}/{total_cols} ({missing_ratio:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = -1\n",
    "srep_type = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(srep_results[srep_type].path)\n",
    "while idx < srep_dfs[srep_type].shape[1] - 1:\n",
    "    idx += 1\n",
    "    target_s = srep_dfs[srep_type].iloc[:, idx]\n",
    "    \n",
    "    if target_s.isna().sum() == 0:\n",
    "        continue\n",
    "\n",
    "    show_nans(target_s, idx)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예측 모델용 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_result_paths = interpolate(pred_outlier_results, interpolators, INTERPOLATED_PTEST_DATA_DIR)\n",
    "len(pred_result_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = get_data_list(INTERPOLATED_PTEST_DATA_DIR)\n",
    "pred_dfs = [tdata.data for tdata in pred_results]\n",
    "len(srep_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 보간되지 못한 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in pred_results:\n",
    "    # 각 열의 결측치 개수를 먼저 계산\n",
    "    na_counts_per_col = data.data.isna().sum()\n",
    "    cols_with_missings = (na_counts_per_col > 0).sum()\n",
    "    total_cols = data.data.shape[1]\n",
    "    missing_ratio = cols_with_missings / total_cols * 100\n",
    "    \n",
    "    print(f\"{data.path}: 결측치가 있는 열 {cols_with_missings}/{total_cols} ({missing_ratio:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = -1\n",
    "pred_type = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(srep_results[pred_type].path)\n",
    "while idx < pred_dfs[pred_type].shape[1] - 1:\n",
    "    idx += 1\n",
    "    target_s = pred_dfs[pred_type].iloc[:, idx]\n",
    "\n",
    "    if target_s.isna().sum() == 0:\n",
    "        continue\n",
    "\n",
    "    # x축은 target_s.index, y축은 NaN이 있는 경우 0, 아닌 경우 NaN\n",
    "    target_s_na = pd.Series(index=target_s.index)\n",
    "    target_s_na[target_s.isna()] = 0\n",
    "    # print(target_s_na.loc[target_s_na == 0])\n",
    "\n",
    "    target_gs = pd.Series(index=target_s.index)\n",
    "    target_resampled = target_s.resample(\"3d\").mean()\n",
    "    target_gs.loc[target_resampled.index] = target_resampled\n",
    "\n",
    "    vis_df_comparison_line_scatter(target_gs, target_s_na)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 보간 성능 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srep_targets = {data.path: data.data.loc[\"2024-10-01\":\"2024-11-01\", :] for data in srep_results}\n",
    "srep_targets[list(srep_targets.keys())[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true: pd.DataFrame, y_pred: pd.DataFrame, skip_na: bool = True):\n",
    "    \"\"\"\n",
    "    두 데이터프레임 간의 MAE와 RMSE를 계산\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    y_true : pd.DataFrame - 참값 데이터프레임 (test_df)\n",
    "    y_pred : pd.DataFrame - 예측값 데이터프레임\n",
    "    skip_na : bool - True면 NaN 값은 계산에서 제외\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict - 전체 및 센서별 메트릭 결과\n",
    "    \"\"\"\n",
    "    # Shape 확인\n",
    "    if y_true.shape != y_pred.shape:\n",
    "        raise ValueError(f\"데이터프레임 shape이 일치하지 않습니다: {y_true.shape} vs {y_pred.shape}\")\n",
    "    \n",
    "    # 전체 데이터에 대한 메트릭\n",
    "    if skip_na:\n",
    "        # NaN이 있는 위치는 계산에서 제외\n",
    "        mask = ~(y_true.isna() | y_pred.isna())\n",
    "        true_values = y_true.values[mask.values]\n",
    "        pred_values = y_pred.values[mask.values]\n",
    "    else:\n",
    "        true_values = y_true.values.flatten()\n",
    "        pred_values = y_pred.values.flatten()\n",
    "    \n",
    "    global_mae = mean_absolute_error(true_values, pred_values)\n",
    "    global_rmse = root_mean_squared_error(true_values, pred_values)\n",
    "    \n",
    "    # 센서별 메트릭 계산\n",
    "    per_sensor_metrics = {}\n",
    "    for col in y_true.columns:\n",
    "        if skip_na:\n",
    "            mask = ~(y_true[col].isna() | y_pred[col].isna())\n",
    "            col_true = y_true.loc[mask, col]\n",
    "            col_pred = y_pred.loc[mask, col]\n",
    "        else:\n",
    "            col_true = y_true[col].dropna()\n",
    "            col_pred = y_pred[col].dropna()\n",
    "            \n",
    "        if len(col_true) > 0:\n",
    "            mae = mean_absolute_error(col_true, col_pred)\n",
    "            rmse = root_mean_squared_error(col_true, col_pred)\n",
    "            per_sensor_metrics[col] = {'mae': mae, 'rmse': rmse, 'count': len(col_true)}\n",
    "    \n",
    "    return {\n",
    "        'global': {'mae': global_mae, 'rmse': global_rmse, 'count': len(true_values)},\n",
    "        'per_sensor': per_sensor_metrics\n",
    "    }\n",
    "\n",
    "def visualize_metrics_comparison(metrics_results, title=\"모델 성능 비교\"):\n",
    "    \"\"\"\n",
    "    여러 모델의 메트릭을 시각화\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    metrics_results : dict - 모델 이름을 키로, calculate_metrics()의 결과를 값으로 하는 딕셔너리\n",
    "    title : str - 그래프 제목\n",
    "    \"\"\"\n",
    "    \n",
    "    # 모델별 전역 메트릭 추출\n",
    "    model_names = list(metrics_results.keys())\n",
    "    mae_values = [metrics['global']['mae'] for metrics in metrics_results.values()]\n",
    "    rmse_values = [metrics['global']['rmse'] for metrics in metrics_results.values()]\n",
    "    \n",
    "    # 시각화\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(16, 6), dpi=120)\n",
    "    \n",
    "    # MAE 그래프\n",
    "    sns.barplot(x=model_names, y=mae_values, ax=axs[0], palette=\"viridis\")\n",
    "    axs[0].set_title('모델별 MAE 비교', fontsize=14)\n",
    "    axs[0].set_ylabel('MAE', fontsize=12)\n",
    "    axs[0].set_ylim(bottom=0)\n",
    "    \n",
    "    # RMSE 그래프\n",
    "    sns.barplot(x=model_names, y=rmse_values, ax=axs[1], palette=\"viridis\")\n",
    "    axs[1].set_title('모델별 RMSE 비교', fontsize=14)\n",
    "    axs[1].set_ylabel('RMSE', fontsize=12)\n",
    "    axs[1].set_ylim(bottom=0)\n",
    "    \n",
    "    # 전체 그래프 타이틀\n",
    "    plt.suptitle(title, fontsize=16, y=1.05)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 수치 표시\n",
    "    for i, ax in enumerate([axs[0], axs[1]]):\n",
    "        values = mae_values if i == 0 else rmse_values\n",
    "        for j, v in enumerate(values):\n",
    "            ax.text(j, v + v*0.01, f'{v:.4f}', ha='center', fontsize=10)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# 사용 예시\n",
    "# 여러 모델의 결과를 test_df와 비교\n",
    "def compare_models_with_test(test_df, prediction_dfs):\n",
    "    \"\"\"\n",
    "    여러 모델의 예측값을 test_df와 비교하여 메트릭 계산 및 시각화\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    test_df : 참값 데이터프레임\n",
    "    prediction_dfs : dict - 모델 이름을 키로, 예측 데이터프레임을 값으로 하는 딕셔너리\n",
    "    \"\"\"\n",
    "    metrics_results = {}\n",
    "    \n",
    "    # 각 모델별 메트릭 계산\n",
    "    for model_name, pred_df in prediction_dfs.items():\n",
    "        metrics = calculate_metrics(test_df, pred_df)\n",
    "        metrics_results[model_name] = metrics\n",
    "        \n",
    "        # 개별 모델 결과 출력\n",
    "        print(f\"\\n{model_name}:\")\n",
    "        print(f\"  MAE: {metrics['global']['mae']:.4f}\")\n",
    "        print(f\"  RMSE: {metrics['global']['rmse']:.4f}\")\n",
    "        print(f\"  유효 샘플 수: {metrics['global']['count']}\")\n",
    "    \n",
    "    # 모델 비교 시각화\n",
    "    visualize_metrics_comparison(metrics_results)\n",
    "    \n",
    "    # 센서별 성능 데이터프레임 생성\n",
    "    sensor_metrics = {}\n",
    "    for model_name, metrics in metrics_results.items():\n",
    "        for sensor, sensor_metric in metrics['per_sensor'].items():\n",
    "            if sensor not in sensor_metrics:\n",
    "                sensor_metrics[sensor] = {}\n",
    "            sensor_metrics[sensor][f\"{model_name}_MAE\"] = sensor_metric['mae'] \n",
    "            sensor_metrics[sensor][f\"{model_name}_RMSE\"] = sensor_metric['rmse']\n",
    "    \n",
    "    return pd.DataFrame(sensor_metrics).T, metrics_results\n",
    "\n",
    "# 사용 예시:\n",
    "# prediction_dfs = {\n",
    "#     \"모델1\": model1_df,\n",
    "#     \"모델2\": model2_df,\n",
    "#     \"모델3\": model3_df\n",
    "# }\n",
    "# sensor_metrics_df, all_metrics = compare_models_with_test(test_df, prediction_dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_metrics_df, all_metrics = compare_models_with_test(test_df, srep_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_all_metrics(y_true: pd.DataFrame, y_pred: pd.DataFrame, skip_na: bool = True):\n",
    "    # Shape 확인\n",
    "    if y_true.shape != y_pred.shape:\n",
    "        raise ValueError(f\"데이터프레임 shape이 일치하지 않습니다: {y_true.shape} vs {y_pred.shape}\")\n",
    "    \n",
    "    # 전체 데이터에 대한 메트릭\n",
    "    if skip_na:\n",
    "        # NaN이 있는 위치는 계산에서 제외\n",
    "        mask = ~(y_true.isna() | y_pred.isna())\n",
    "        true_values = y_true.values[mask.values]\n",
    "        pred_values = y_pred.values[mask.values]\n",
    "    else:\n",
    "        true_values = y_true.values.flatten()\n",
    "        pred_values = y_pred.values.flatten()\n",
    "    \n",
    "    mae = mean_absolute_error(true_values, pred_values)\n",
    "    rmse = root_mean_squared_error(true_values, pred_values)\n",
    "\n",
    "    return mae, rmse\n",
    "\n",
    "def calc_each_metrics(y_true: pd.DataFrame, y_pred: pd.DataFrame, skip_na: bool = True):\n",
    "    # Shape 확인\n",
    "    if y_true.shape != y_pred.shape:\n",
    "        raise ValueError(f\"데이터프레임 shape이 일치하지 않습니다: {y_true.shape} vs {y_pred.shape}\")\n",
    "    \n",
    "    # 센서별 메트릭 계산\n",
    "    per_sensor_metrics = {}\n",
    "    for col in y_true.columns:\n",
    "        if skip_na:\n",
    "            mask = ~(y_true[col].isna() | y_pred[col].isna())\n",
    "            col_true = y_true.loc[mask, col]\n",
    "            col_pred = y_pred.loc[mask, col]\n",
    "        else:\n",
    "            col_true = y_true[col].dropna()\n",
    "            col_pred = y_pred[col].dropna()\n",
    "            \n",
    "        if len(col_true) > 0:\n",
    "            mae = mean_absolute_error(col_true, col_pred)\n",
    "            rmse = root_mean_squared_error(col_true, col_pred)\n",
    "            per_sensor_metrics[col] = {'mae': mae, 'rmse': rmse, 'count': len(col_true)}\n",
    "    \n",
    "    return per_sensor_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_list = []\n",
    "rmse_list = []\n",
    "\n",
    "for model_name, pred_df in tqdm(srep_targets.items()):\n",
    "    mae, rmse = calc_all_metrics(test_df, pred_df)\n",
    "    mae_list.append((mae, model_name))\n",
    "    rmse_list.append((rmse, model_name))\n",
    "\n",
    "mae_list.sort(key=lambda x: x[0])\n",
    "rmse_list.sort(key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_mae_dict = {}\n",
    "sensor_rmse_dict = {}\n",
    "\n",
    "for model_name, pred_df in tqdm(srep_targets.items()):\n",
    "    results = calc_each_metrics(test_df, pred_df)\n",
    "\n",
    "    mae_result = {col: result['mae'] for col, result in results.items()}\n",
    "    rmse_result = {col: result['rmse'] for col, result in results.items()}\n",
    "    sensor_mae_dict[os.path.basename(model_name)] = mae_result\n",
    "    sensor_rmse_dict[os.path.basename(model_name)] = rmse_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(sensor_mae_dict).T.to_excel(\"./output/srep_sensor_mae.xlsx\")\n",
    "pd.DataFrame(sensor_rmse_dict).T.to_excel(\"./output/srep_sensor_rmse.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결과 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_id = \"1690003706\"\n",
    "strue = test_df[sensor_id]\n",
    "strue.name = sensor_id + \"(True)\"\n",
    "s1 = srep_targets[\"./output/interpolated/stest/hzscore-time_mean.h5\"][sensor_id]\n",
    "s2 = srep_targets[\"./output/interpolated/stest/mad-linear.h5\"][sensor_id]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "s1.plot()\n",
    "strue.plot()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "s2.plot()\n",
    "strue.plot()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
