{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA for Incheon Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "Import necessary libraries including pandas, numpy, matplotlib, seaborn, and specialized libraries like geopandas and missingno. Set up visualization parameters and define utility paths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Tuple\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from metr.components import TrafficData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and Create Utility Paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP_DATA_OF_SENSORS = \"../datasets/metr-imc/nodelink/imc_link.shp\"\n",
    "TRAFFIC_RAW_PATH = \"../datasets/metr-imc/metr-imc.h5\"\n",
    "METADATA_RAW_PATH = \"../datasets/metr-imc/metadata.h5\"\n",
    "OUTLIER_OUTPUT_DIR = \"./output/outlier_processed\"\n",
    "INTERPOLATED_OUTPUT_DIR = \"./output/interpolated\"\n",
    "FINAL_OUTPUT_DIR = \"./output/final\"\n",
    "PREDICTION_OUTPUT_DIR = \"./output/prediction\"\n",
    "\n",
    "os.makedirs(OUTLIER_OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(INTERPOLATED_OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(FINAL_OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(PREDICTION_OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up visualization parameters\n",
    "plt.rcParams[\"font.family\"] = \"AppleGothic\"  # Use AppleGothic for better font rendering\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False  # Prevent negative sign rendering issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing\n",
    "Load traffic data from HDF files, inspect initial data structure, and perform basic filtering to remove sensors with excessive missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = TrafficData.import_from_hdf(TRAFFIC_RAW_PATH)\n",
    "raw_df = raw.data\n",
    "raw_df.iloc[:, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = pd.read_hdf(METADATA_RAW_PATH)\n",
    "metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the initial structure of the data\n",
    "print(\"Initial Data Shape:\", raw_df.shape)\n",
    "print(\"Initial Data Columns:\", raw_df.columns[:5])  # Display first 5 columns\n",
    "print(\"Initial Data Sample:\")\n",
    "print(raw_df[raw_df.columns[:4]].head(), end=\"\\n\\n\")\n",
    "\n",
    "# Check for missing values in the dataset\n",
    "missing_values_count = raw_df.isnull().sum().sum()\n",
    "print(f\"Total Missing Values: {missing_values_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_missing_rate = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out sensors with more than 50% missing values\n",
    "threshold = raw_df.shape[0] * max_missing_rate\n",
    "df = raw_df.dropna(thresh=threshold, axis=1)\n",
    "\n",
    "# Display the shape of the filtered data\n",
    "print(\"Filtered Data Shape:\", df.shape)\n",
    "print(f\"Removed Sensors: {raw_df.shape[1] - df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Analysis and Summaries\n",
    "Calculate summary statistics for the dataset, analyze the distribution of values, and identify general patterns in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate summary statistics for the filtered dataset\n",
    "summary_stats = df.describe().transpose()\n",
    "print(\"Summary Statistics:\")\n",
    "print(summary_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_limit = 1000\n",
    "\n",
    "# Analyze the distribution of values across all sensors\n",
    "value_distribution = df.stack().reset_index(drop=True)\n",
    "values_low = value_distribution[value_distribution < low_limit]\n",
    "values_high = value_distribution[value_distribution >= low_limit]\n",
    "\n",
    "# 2행 1열의 subplot 생성\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "# 상단 그래프 - values_low\n",
    "sns.histplot(values_low, bins=150, kde=True, color=\"blue\", ax=ax1)\n",
    "ax1.set_title(f\"Traffic Volume Distribution (< {low_limit})\")\n",
    "ax1.set_xlabel(\"Traffic Volume\")\n",
    "ax1.set_ylabel(\"Frequency\")\n",
    "ax1.grid(True)\n",
    "\n",
    "# 하단 그래프 - values_high\n",
    "sns.histplot(values_high, bins=200, color=\"red\", ax=ax2)\n",
    "ax2.set_title(f\"Traffic Volume Distribution (≥ {low_limit})\")\n",
    "ax2.set_xlabel(\"Traffic Volume\")\n",
    "ax2.set_ylabel(\"Frequency\")\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify sensors with the highest and lowest mean traffic volume\n",
    "sensor_means = df.mean()\n",
    "highest_mean_sensor = sensor_means.idxmax()\n",
    "lowest_mean_sensor = sensor_means.idxmin()\n",
    "print(f\"Sensor with Highest Mean Traffic Volume: {highest_mean_sensor} ({sensor_means[highest_mean_sensor]:.2f})\")\n",
    "print(f\"Sensor with Lowest Mean Traffic Volume: {lowest_mean_sensor} ({sensor_means[lowest_mean_sensor]:.2f})\")\n",
    "\n",
    "# Plot the mean traffic volume for all sensors\n",
    "plt.figure(figsize=(12, 6))\n",
    "sensor_means.sort_values(ascending=False).plot(kind=\"bar\", color=\"blue\", alpha=0.7)\n",
    "plt.title(\"Mean Traffic Volume by Sensor\")\n",
    "plt.xlabel(\"Sensors\")\n",
    "plt.ylabel(\"Mean Traffic Volume\")\n",
    "plt.xticks([])  # x축 레이블 제거\n",
    "plt.grid(axis=\"y\")\n",
    "plt.ylim(top=3000)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and display the percentage of missing values for each sensor\n",
    "missing_percentage = df.isnull().mean() * 100\n",
    "print(\"Percentage of Missing Values by Sensor:\")\n",
    "print(missing_percentage.sort_values(ascending=False))\n",
    "\n",
    "# Visualize the percentage of missing values\n",
    "plt.figure(figsize=(12, 6))\n",
    "missing_percentage.sort_values(ascending=False).plot(kind=\"bar\", color=\"red\", alpha=0.7)\n",
    "plt.title(\"Percentage of Missing Values by Sensor\")\n",
    "plt.xlabel(\"Sensors\")\n",
    "plt.ylabel(\"Missing Percentage (%)\")\n",
    "plt.xticks([])  # x축 레이블 제거\n",
    "plt.grid(axis=\"y\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하나의 센서에 대한 히스토그램 분석도 실시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate histograms to examine the distribution of traffic volumes\n",
    "def plot_histogram(df: pd.DataFrame, column: str, title: str, bins: int = 50, x_max: float = None, exclude_zero: bool = False):\n",
    "    values = df[column].dropna()  # Remove NaN values\n",
    "    if exclude_zero:\n",
    "        values = values[values != 0]  # Exclude zero values if specified\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(values, bins=bins, kde=True, color=\"blue\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Traffic Volume\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.grid(True)\n",
    "    \n",
    "    if x_max is not None:\n",
    "        plt.xlim(right=x_max)  # Set maximum x-axis value if specified\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_id = df.columns[0]  # Select the first sensor as an example\n",
    "plot_histogram(df, sensor_id, f\"Histogram for Sensor {sensor_id}\", bins=50, x_max=2000, exclude_zero=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal Pattern Analysis\n",
    "Visualize traffic patterns by time of day, day of week, and over longer time periods. Create functions to plot mean values by hour and compare trends across different time periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for temporal pattern analysis\n",
    "\n",
    "\n",
    "def plot_mean_by_hour(df: pd.DataFrame, title: str, figsize: Tuple[int, int] = (10, 6)):\n",
    "    \"\"\"\n",
    "    Plot the mean traffic volume by hour of the day.\n",
    "    \"\"\"\n",
    "    hourly_means = df.groupby(df.index.hour).mean().mean(axis=1)\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.lineplot(x=hourly_means.index, y=hourly_means.values, marker=\"o\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Hour of Day\")\n",
    "    plt.ylabel(\"Mean Traffic Volume\")\n",
    "    plt.grid(True)\n",
    "    plt.xticks(range(0, 24))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_mean_by_day_of_week(\n",
    "    df: pd.DataFrame, title: str, figsize: Tuple[int, int] = (10, 6)\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot the mean traffic volume by day of the week.\n",
    "    \"\"\"\n",
    "    day_of_week_means = df.groupby(df.index.dayofweek).mean().mean(axis=1)\n",
    "    day_labels = [\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"]\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.barplot(\n",
    "        x=day_of_week_means.index,\n",
    "        y=day_of_week_means.values,\n",
    "        palette=\"viridis\",\n",
    "    )\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Day of Week\")\n",
    "    plt.ylabel(\"Mean Traffic Volume\")\n",
    "    plt.xticks(ticks=range(7), labels=day_labels)\n",
    "    plt.grid(axis=\"y\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_mean_by_month(\n",
    "    df: pd.DataFrame, title: str, figsize: Tuple[int, int] = (10, 6)\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot the mean traffic volume by month.\n",
    "    \"\"\"\n",
    "    monthly_means = df.groupby(df.index.month).mean().mean(axis=1)\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.lineplot(\n",
    "        x=monthly_means.index, y=monthly_means.values, marker=\"o\", color=\"green\"\n",
    "    )\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Month\")\n",
    "    plt.ylabel(\"Mean Traffic Volume\")\n",
    "    plt.grid(True)\n",
    "    plt.xticks(range(1, 13))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Apply the functions to the filtered data\n",
    "plot_mean_by_hour(df, \"Mean Traffic Volume by Hour of Day\")\n",
    "plot_mean_by_day_of_week(df, \"Mean Traffic Volume by Day of Week\")\n",
    "plot_mean_by_month(df, \"Mean Traffic Volume by Month\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Detection and Analysis\n",
    "Implement outlier detection using statistical methods (z-score, IQR) and domain knowledge about theoretical road capacities. Visualize outliers and assess their impact on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for outlier detection and visualization\n",
    "def detect_outliers_zscore(df: pd.DataFrame, threshold: float = 3.0) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Detect outliers using the z-score method. 여기서 z-score는 전체 데이터의 평균과 표준편차를 사용.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing the data.\n",
    "    - threshold: Z-score threshold for identifying outliers.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with boolean values indicating outliers (True for outliers).\n",
    "    \"\"\"\n",
    "    z_scores = (df - df.mean()) / df.std()\n",
    "    return z_scores.abs() > threshold\n",
    "\n",
    "\n",
    "def detect_outliers_iqr(df: pd.DataFrame, multiplier: float = 1.5) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Detect outliers using the IQR method. 전체 데이터 기반 IQR을 사용.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing the data.\n",
    "    - multiplier: Multiplier for the IQR range to identify outliers.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with boolean values indicating outliers (True for outliers).\n",
    "    \"\"\"\n",
    "    Q1 = df.quantile(0.25)\n",
    "    Q3 = df.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    return (df < (Q1 - multiplier * IQR)) | (df > (Q3 + multiplier * IQR))\n",
    "\n",
    "\n",
    "# Road capacity-based outlier detection\n",
    "def detect_outliers_road_caps(\n",
    "    df: pd.DataFrame,\n",
    "    metadata: pd.DataFrame,\n",
    "    adjustment_rate: float = 1.5,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Detect outliers based on theoretical road capacities using domain knowledge.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing the data.\n",
    "    - metadata: Metadata containing road information.\n",
    "    - adjustment_rate: Multiplier for the theoretical road capacity.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with boolean values indicating outliers (True for outliers).\n",
    "    \"\"\"\n",
    "    \n",
    "    capacity_map = {}\n",
    "    for _, row in metadata.iterrows():\n",
    "        speed_limit = row[\"MAX_SPD\"]\n",
    "        lanes = row[\"LANES\"]\n",
    "        base_capacity = (2200 - 10 * (100 - speed_limit)) * lanes\n",
    "        capacity_map[row[\"LINK_ID\"]] = base_capacity * adjustment_rate\n",
    "\n",
    "    outliers = pd.DataFrame(False, index=df.index, columns=df.columns)\n",
    "    for col in df.columns:\n",
    "        if col in capacity_map:\n",
    "            outliers[col] = df[col] > capacity_map[col]\n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_outliers_in_sensor(\n",
    "    sensor_series: pd.Series, outlier: pd.Series, title: str, alpha: float = 0.7\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualize outliers on a line plot.\n",
    "\n",
    "    Parameters:\n",
    "    - sensor_series: Original Series data of target sensor.\n",
    "    - outliers: Boolean series indicating outliers of target sensor. The index should match the original series.\n",
    "    - title: Title of the plot.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.plot(\n",
    "        sensor_series.index,\n",
    "        sensor_series,\n",
    "        label=f\"Sensor {sensor_series.name}\",\n",
    "        alpha=alpha,\n",
    "    )\n",
    "    \n",
    "    outlier_data = sensor_series[outlier]\n",
    "    plt.scatter(\n",
    "        outlier_data.index,  # 이상치의 인덱스(시간)\n",
    "        outlier_data.values,  # 이상치 값\n",
    "        color=\"red\",\n",
    "        label=f\"Outliers {sensor_series.name}\",\n",
    "        s=10,\n",
    "    )\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Traffic Volume\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect outliers using z-score\n",
    "zscore_outliers = detect_outliers_zscore(df, threshold=3.0)\n",
    "\n",
    "target_sensor_data = df.iloc[:, 0]  # Select the first sensor as an example\n",
    "target_sensor_outliers = zscore_outliers.iloc[:, 0]\n",
    "# Select the first sensor's outliers\n",
    "\n",
    "visualize_outliers_in_sensor(\n",
    "    target_sensor_data, target_sensor_outliers, \"Outliers Detected by Z-Score Method\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect outliers using IQR methods\n",
    "iqr_outliers = detect_outliers_iqr(df, multiplier=1.5)\n",
    "\n",
    "target_sensor_data = df.iloc[:, 0]  # Select the first sensor as an example\n",
    "target_sensor_outliers = iqr_outliers.iloc[:, 0]\n",
    "# Select the first sensor's outliers\n",
    "\n",
    "visualize_outliers_in_sensor(\n",
    "    target_sensor_data, target_sensor_outliers, \"Outliers Detected by IQR Method\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect outliers using domain knowledge\n",
    "road_cap_outliers = detect_outliers_road_caps(df, metadata_df, adjustment_rate=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 열에 True 값(이상치)이 하나라도 있는 센서만 선택\n",
    "cols_with_outliers = road_cap_outliers.any()\n",
    "road_cap_outliers_filtered = road_cap_outliers.loc[:, cols_with_outliers]\n",
    "\n",
    "# True가 있는 열의 수와 전체 열 수 출력\n",
    "print(f\"전체 센서 수: {road_cap_outliers.shape[1]}개\")\n",
    "print(f\"Road Cap. 이상치가 있는 센서 수: {road_cap_outliers_filtered.shape[1]}개\")\n",
    "\n",
    "# 결과 출력\n",
    "road_cap_outliers_filtered.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_sensor_data = df.loc[:, \"1640048000\"]  # Select the first sensor as an example\n",
    "target_sensor_outliers = road_cap_outliers.loc[:, \"1640048000\"]\n",
    "# Select the first sensor's outliers\n",
    "# 1660033301 or 1640049000\n",
    "# 1640048000는 확실한 이상치만 있는 센서\n",
    "\n",
    "# Visualize outliers detected by domain knowledge\n",
    "visualize_outliers_in_sensor(\n",
    "    target_sensor_data,\n",
    "    target_sensor_outliers,\n",
    "    \"Outliers Detected by Road Capacity Method\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess the impact of outliers on the dataset\n",
    "def assess_outlier_impact(df: pd.DataFrame, outliers: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Assess the impact of outliers on the dataset by calculating the percentage of outliers.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: Original DataFrame containing the data.\n",
    "    - outliers: DataFrame with boolean values indicating outliers.\n",
    "    \"\"\"\n",
    "    total_values = df.size\n",
    "    total_outliers = outliers.sum().sum()\n",
    "    outlier_percentage = (total_outliers / total_values) * 100\n",
    "    print(f\"Total Outliers: {total_outliers}\")\n",
    "    print(f\"Percentage of Outliers: {outlier_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess the impact of outliers detected by each method\n",
    "print(\"Impact of Z-Score Outliers:\")\n",
    "assess_outlier_impact(df, zscore_outliers)\n",
    "\n",
    "print(\"\\nImpact of IQR Outliers:\")\n",
    "assess_outlier_impact(df, iqr_outliers)\n",
    "\n",
    "print(\"\\nImpact of Domain Knowledge Outliers:\")\n",
    "assess_outlier_impact(df, road_cap_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Data Patterns\n",
    "Analyze missing data patterns using visualization tools like missingno. Calculate missing data statistics by sensor and time period, and identify systematic patterns in data missingness.\n",
    "\n",
    "Analyze missing data patterns using visualization tools like missingno\n",
    "Calculate missing data statistics by sensor and time period\n",
    "Identify systematic patterns in data missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_columns = np.random.choice(\n",
    "    df.columns,\n",
    "    min(500, df.shape[1]),\n",
    "    replace=False,\n",
    ")\n",
    "sampled_df = df[sample_columns]\n",
    "\n",
    "# Visualize missing data patterns using missingno\n",
    "plt.figure(figsize=(12, 6))\n",
    "msno.matrix(sampled_df, sparkline=False)\n",
    "plt.title(\"Missing Data Matrix\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "msno.heatmap(sampled_df, cmap=\"viridis\")\n",
    "plt.title(\"Missing Data Correlation Heatmap\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "msno.bar(sampled_df, color=\"blue\", fontsize=12)\n",
    "plt.title(\"Missing Data Bar Chart\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate missing data statistics by sensor\n",
    "missing_by_sensor = df.isnull().sum()\n",
    "missing_percentage_by_sensor = (missing_by_sensor / df.shape[0]) * 100\n",
    "missing_stats = pd.DataFrame({\n",
    "    \"Missing Count\": missing_by_sensor,\n",
    "    \"Missing Percentage (%)\": missing_percentage_by_sensor\n",
    "}).sort_values(by=\"Missing Percentage (%)\", ascending=False)\n",
    "\n",
    "print(\"Missing Data Statistics by Sensor:\")\n",
    "print(missing_stats.head(10))  # Display top 10 sensors with the most missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate missing data statistics by time period\n",
    "missing_by_time = df.isnull().sum(axis=1)\n",
    "missing_percentage_by_time = (missing_by_time / df.shape[1]) * 100\n",
    "missing_time_stats = pd.DataFrame({\n",
    "    \"Missing Count\": missing_by_time,\n",
    "    \"Missing Percentage (%)\": missing_percentage_by_time\n",
    "}).sort_index()\n",
    "\n",
    "print(\"Missing Data Statistics by Time Period:\")\n",
    "print(missing_time_stats.head(10))  # Display first 10 time periods with missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missing data statistics by time period\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(missing_time_stats.index, missing_time_stats[\"Missing Percentage (%)\"], label=\"Missing Percentage\", color=\"red\")\n",
    "plt.title(\"Missing Data Percentage by Time Period\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Missing Percentage (%)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify systematic patterns in missing data\n",
    "missing_patterns = df.isnull().astype(int)\n",
    "correlation_matrix = missing_patterns.corr()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(correlation_matrix, cmap=\"coolwarm\", annot=False, cbar=True)\n",
    "plt.title(\"Correlation of Missing Data Between Sensors\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Data Visualization\n",
    "Use geopandas to visualize the geographical distribution of sensors, highlighting those with different characteristics (high missing rates, outliers, etc.).\n",
    "\n",
    "이 부분은 좀 더 수정할 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load geographical data for sensors\n",
    "gdf_raw = gpd.read_file(MAP_DATA_OF_SENSORS)\n",
    "gdf_raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge geographical data with missing data statistics\n",
    "missing_stats = df.isnull().mean() * 100  # Calculate missing percentage\n",
    "missing_stats_df = pd.DataFrame({\n",
    "    \"LINK_ID\": missing_stats.index,\n",
    "    \"Missing Percentage\": missing_stats.values\n",
    "})\n",
    "gdf = gdf_raw.merge(missing_stats_df, on=\"LINK_ID\", how=\"left\")\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge geographical data with outlier statistics\n",
    "outlier_counts = road_cap_outliers.sum()  # Count outliers per sensor\n",
    "outlier_stats_df = pd.DataFrame({\n",
    "    \"LINK_ID\": outlier_counts.index,\n",
    "    \"Outlier Count\": outlier_counts.values\n",
    "})\n",
    "gdf = gdf.merge(outlier_stats_df, on=\"LINK_ID\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_missing_sensors = gdf[gdf[\"Missing Percentage\"] > 50]\n",
    "high_missing_sensors.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_outlier_sensors = gdf[gdf[\"Outlier Count\"] > 0]\n",
    "high_outlier_sensors.explore(color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sensors with high outlier counts\n",
    "high_outlier_sensors = gdf[gdf[\"Outlier Count\"] > 0]\n",
    "high_outlier_sensors.explore(color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize all sensors with missing and outlier statistics\n",
    "plt.figure(figsize=(12, 8))\n",
    "gdf.plot(column=\"Missing Percentage\", cmap=\"Oranges\", legend=True, edgecolor=\"black\")\n",
    "plt.title(\"Geographical Plots\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
