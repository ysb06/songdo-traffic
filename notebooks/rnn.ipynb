{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers and Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 실험 환경 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사용 패키지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "from metr.components import TrafficData, Metadata\n",
    "import geopandas as gpd\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"AppleGothic\"\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False  # 음수 부호 깨짐 방지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 주요 데이터 경로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP_DATA_OF_SENSORS = \"../datasets/metr-imc/nodelink/imc_link.shp\"\n",
    "TRAFFIC_RAW_PATH = \"../datasets/metr-imc/metr-imc.h5\"\n",
    "METADATA_RAW_PATH = \"../datasets/metr-imc/metadata.h5\"\n",
    "OUTLIER_OUTPUT_DIR = \"./output/outlier_processed\"\n",
    "INTERPOLATED_OUTPUT_DIR = \"./output/interpolated\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Raw Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw 데이터 로딩\n",
    "\n",
    "Raw 데이터는 원래 인천시에서 제공되었던 형태에서 현재 METR-LA와 같은 형태로 변환되어 있다. 행은 시간을 나타내고 열은 각 도로의 센서를 나타낸다. 형식은 전국표준노드링크의 Link ID를 나타내며 string 형식으로 지정되어 있다.\n",
    "\n",
    "본 연구에서는 2024년 3월부터 2024년 9월까지의 데이터를 사용한다. 데이터가 어느정도 깔끔해서의 이유도 있지만 공식적으로는 연구 시작 지점에서 RNN 모델의 성능이 가장 높게 나오는 데이터의 길이이기 때문이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = TrafficData.import_from_hdf(TRAFFIC_RAW_PATH).data\n",
    "raw_df = raw_df.loc[\"2024-03-01\":\"2024-10-01\", :]\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원래 표준노드링크는 전국의 데이터를 포함하며 아래는 그 중 인천시에 해당하는 데이터만 추출한 데이터이다. 해당 데이터는 2024년 3월 25일에 최신화된 데이터이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_gdf = gpd.read_file(MAP_DATA_OF_SENSORS)\n",
    "print(geo_gdf.shape)\n",
    "geo_gdf.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하지만, 인천시에서는 모든 도로에 대해 교통량을 측정하지 않으며 교통량을 측정하고 있는 도로는 다음과 같다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geo_gdf에서 LINK_ID가 raw_df.columns에 있는 것만 남기기\n",
    "geo_gdf_with_traffic: gpd.GeoDataFrame = geo_gdf[geo_gdf[\"LINK_ID\"].isin(raw_df.columns)]\n",
    "\n",
    "print(geo_gdf_with_traffic.shape)\n",
    "geo_gdf_with_traffic.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "메타데이터는 표준노드링크에 명시된 내용을 추출했으며 각 센서에 해당하는 도로의 정보를 포함한다. 본 연구에서는 도로 허용 용량을 계산할 때에만 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_metadata_df = Metadata.import_from_hdf(METADATA_RAW_PATH).data\n",
    "raw_metadata_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of the dataset:\", raw_df.shape)\n",
    "print(\"Description of the Incheon dataset\")\n",
    "print(raw_df.reset_index(drop=True).melt()[\"value\"].describe().apply(lambda x: format(x, '.4f')))\n",
    "print()\n",
    "\n",
    "total_missing_values_count = raw_df.isnull().sum().sum()\n",
    "print(\"Total missing values count:\", total_missing_values_count, f\"({total_missing_values_count / raw_df.size * 100:.4f}%)\")\n",
    "print()\n",
    "\n",
    "sensors_with_mv = raw_df.isnull().any(axis=0)\n",
    "print(\"Sensors with missing values count:\", sensors_with_mv.sum(), f\"({sensors_with_mv.sum() / raw_df.shape[1] * 100:.4f}%)\")\n",
    "print(\"Sensors with no missing values count:\", (~sensors_with_mv).sum(), f\"({(~sensors_with_mv).sum() / raw_df.shape[1] * 100:.4f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots of Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_by_time(df: pd.DataFrame, title: str, size: Tuple=(10, 6)):\n",
    "    groups = df.groupby([df.index.hour, df.index.minute, df.index.second])\n",
    "    mean_df = groups.apply(lambda x: x.stack().mean())\n",
    "    mean_df.index = [\n",
    "        datetime(year=1970, month=1, day=1, hour=h, minute=m, second=s)\n",
    "        for h, m, s in mean_df.index\n",
    "    ]\n",
    "    plot_by_time(mean_df, title, size)\n",
    "\n",
    "\n",
    "def plot_by_time(df: pd.DataFrame, title: str, size: Tuple=(12, 6)):\n",
    "    plt.figure(figsize=size)\n",
    "    sns.lineplot(x=df.index, y=df.values)\n",
    "    # plt.gca().xaxis.set_major_formatter(mdates.DateFormatter(\"%H:%M:%S\"))\n",
    "\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Average Value\")\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_by_days(df: pd.DataFrame, name: str):\n",
    "    data_list = []\n",
    "\n",
    "    for day in range(7):\n",
    "        day_data = df[df.index.dayofweek == day]\n",
    "        numeric_cols = day_data.select_dtypes(include=[np.number]).columns\n",
    "        day_numeric = day_data[numeric_cols]\n",
    "        values = day_numeric.values.flatten()\n",
    "        values = values[~np.isnan(values)]\n",
    "        df_day = pd.DataFrame({\"Volumes\": values, \"Days\": day})\n",
    "        data_list.append(df_day)\n",
    "\n",
    "    df_all = pd.concat(data_list, ignore_index=True)\n",
    "\n",
    "    # 요일 레이블 매핑\n",
    "    day_labels = {0: \"Mon\", 1: \"Tue\", 2: \"Wed\", 3: \"Thu\", 4: \"Fri\", 5: \"Sat\", 6: \"Sun\"}\n",
    "    df_all[\"Days\"] = df_all[\"Days\"].map(day_labels)\n",
    "    df_all[\"Days\"] = pd.Categorical(\n",
    "        df_all[\"Days\"],\n",
    "        categories=[\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"],\n",
    "        ordered=True,\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(\n",
    "        x=\"Days\",\n",
    "        y=\"Volumes\",\n",
    "        data=df_all,\n",
    "        order=[\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"],\n",
    "    )\n",
    "    plt.xlabel(\"Days\")\n",
    "    plt.ylabel(\"Traffic Volumes\")\n",
    "    plt.title(f\"Data by Day in {name}\")\n",
    "    plt.grid(True)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    formatter = FuncFormatter(lambda x, pos: f\"{int(x):,}\")\n",
    "    ax.yaxis.set_major_formatter(formatter)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_hist(\n",
    "    df: pd.DataFrame,\n",
    "    name: str,\n",
    "    exclude_zero: bool = False,\n",
    "    y_max: float = None,\n",
    "    x_max: float = None,\n",
    "    bins: int = 50,\n",
    "):\n",
    "    values = df.values.flatten()\n",
    "    values = values[~np.isnan(values)]\n",
    "\n",
    "    if exclude_zero:\n",
    "        values = values[values != 0]\n",
    "\n",
    "    if x_max is not None:\n",
    "        bin_edges = np.histogram_bin_edges(\n",
    "            values, bins=bins, range=(values.min(), x_max)\n",
    "        )\n",
    "        bin_edges = np.append(bin_edges, np.inf)\n",
    "    else:\n",
    "        bin_edges = bins\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(values, bins=bin_edges, kde=True)\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.title(f\"Histogram of {name}\")\n",
    "    plt.grid(True)\n",
    "\n",
    "    if y_max is not None:\n",
    "        plt.ylim(top=y_max)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    formatter = FuncFormatter(lambda x, _: f\"{int(x):,}\")\n",
    "    ax.yaxis.set_major_formatter(formatter)\n",
    "    ax.xaxis.set_major_formatter(formatter)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 그래프는 전체 데이터를 평균을 내고 추세를 본 것이다. 일반적으로 대부분의 각 센서의 데이터는 아래와 같은 형태를 보인다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mean_by_time(raw_df, \"Plots by Time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래는 요일 별 데이터의 분포를 나타낸 것이다. 2024년 3월 이전의 데이터는 말도 안 되는 값(>100000)들이 많이 있는 것을 확인하기도 했지만 현재 범위(2024-03 ~ 2024-09)의 데이터는 극단적인 값들은 크게 없는 것으로 보인다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_by_days(raw_df, \"Plots by Days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래는 데이터 구간 별 데이터 분포를 나타낸다. 20000만개 이상은 그래프에 표시하지 않았지만 대부분의 데이터는 교통량이 2000아래에 분포해 있다. 또한 교통량이 2000이상 넘어가는 도로는 대체로 고속도로이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(raw_df, \"Data Histogram\", y_max=20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반적으로 데이터의 그래프는 아래와 같다. 특정 기간에서 데이터가 증가한 것을 확인할 수 있다. 그 외에도 어떤 그래프의 경우 말도 안되는 값을 가지는 경우도 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_data = raw_df.iloc[:, 1]\n",
    "plot_by_time(target_data, f\"Plots by Time: {target_data.name}\")\n",
    "geo_gdf[geo_gdf[\"LINK_ID\"] == target_data.name].explore(\n",
    "    style_kwds={\n",
    "        \"color\": \"red\",  # 선 색상\n",
    "        \"weight\": 5,  # 선 굵기 (픽셀 단위)\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 고속도로\n",
    "target_data = raw_df.loc[:, \"1610002900\"]\n",
    "plot_by_time(target_data, f\"Plots by Time: {target_data.name}\")\n",
    "geo_gdf[geo_gdf[\"LINK_ID\"] == target_data.name].explore(\n",
    "    style_kwds={\n",
    "        \"color\": \"red\",  # 선 색상\n",
    "        \"weight\": 5,  # 선 굵기 (픽셀 단위)\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2024년 3월 이전의 데이터는 100,000이 넘어가는 비정상적 데이터도 확인했지만 현재 범위의 데이터에서는 비정상적으로는 보이지 않는다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while idx < raw_df.shape[1]:    \n",
    "    idx += 1\n",
    "    target_data = raw_df.iloc[:, idx]\n",
    "    if target_data[target_data > 10000].any():\n",
    "        break\n",
    "\n",
    "plot_by_time(target_data, f\"Plots by Time: {target_data.name}\")\n",
    "geo_gdf[geo_gdf[\"LINK_ID\"] == target_data.name].explore(\n",
    "    style_kwds={\n",
    "        \"color\": \"red\",  # 선 색상\n",
    "        \"weight\": 5,  # 선 굵기 (픽셀 단위)\n",
    "    },\n",
    ")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"1640332801\"과 같은 센서의 경우 결측치가 대부분이고 유효한 값은 거의 없는 것으로 보인다. 해당 위치의 경우 차량통행이 꽤 있는 곳이며 측정이 제대로 이루어지지 않았음을 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while idx < raw_df.shape[1]:    \n",
    "    idx += 1\n",
    "    target_data = raw_df.iloc[:, idx]\n",
    "    if target_data.isna().sum() > 3000:\n",
    "        break\n",
    "\n",
    "plot_by_time(target_data, f\"Plots by Time: {target_data.name}\")\n",
    "geo_gdf[geo_gdf[\"LINK_ID\"] == target_data.name].explore(\n",
    "    style_kwds={\n",
    "        \"color\": \"red\",  # 선 색상\n",
    "        \"weight\": 5,  # 선 굵기 (픽셀 단위)\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기본 Outlier 처리\n",
    "\n",
    "앞서 본 연구에서 다음 이상치 처리를 기본으로 적용한다.\n",
    "\n",
    "1. 결측치 주변 0을 제거\n",
    "  경험적 데이터 분석 결과를 바탕으로 결측치 주변 0이 \n",
    "2. 이론적 도로 허용 용량 기반 제거 (1.5배 또는 2.0배까지 허용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from songdo_rnn.preprocessing.outlier import remove_base_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = remove_base_outliers(\n",
    "    start_datetime=\"2024-03-01 00:00:00\",\n",
    "    end_datetime=\"2024-09-30 23:00:00\",\n",
    "    traffic_capacity_adjustment_rate=2.0,\n",
    "    raw_path=TRAFFIC_RAW_PATH,\n",
    "    metadata_path=METADATA_RAW_PATH,\n",
    "    output_dir=OUTLIER_OUTPUT_DIR,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df = TrafficData.import_from_hdf(result_path).data\n",
    "base_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기본 Outlier 처리 결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_fromto_df(df1: pd.Series, df2: pd.Series, title: str = \"\"):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    df1.plot(label=\"Original Data\", color=\"red\")\n",
    "    df2.plot(label=\"Processed Data\", color=\"blue\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx += 1\n",
    "\n",
    "original_data = raw_df.iloc[:, idx]\n",
    "target_data = base_df.iloc[:, idx]\n",
    "\n",
    "compare_fromto_df(original_data, target_data, title=f\"Origin vs Target: {original_data.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while idx < raw_df.shape[1]:\n",
    "    idx += 1\n",
    "    original_data = raw_df.iloc[:, idx]\n",
    "    target_data = base_df.iloc[:, idx]\n",
    "\n",
    "    if original_data.isna().sum() == target_data.isna().sum():\n",
    "        continue\n",
    "\n",
    "    print(original_data.name, \":\" , original_data.isna().sum())\n",
    "    print(target_data.name, \":\", target_data.isna().sum())\n",
    "\n",
    "    compare_fromto_df(original_data, target_data, title=f\"Origin vs Target: {original_data.name}\")\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "극단적으로 결측치가 많은 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_sensor_idx = \"1640332801\"\n",
    "original_data = raw_df[target_sensor_idx]\n",
    "target_data = base_df[target_sensor_idx]\n",
    "\n",
    "compare_fromto_df(original_data, target_data, title=f\"Origin vs Target: {original_data.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odata = original_data[original_data.notna() & original_data > 0]\n",
    "tdata = target_data[odata.index]\n",
    "print(odata.name)\n",
    "print(tdata.name)\n",
    "for o, t in zip(odata.items(), tdata.items()):\n",
    "    print(o[0], o[1], t[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 코드는 0제거 외에 허용 용량에 따른 제거된 사례를 확인하는 코드임. 테스트 상 2.0배를 넘어가는 경우는 종종 있지만 2.5를 넘어가지는 않음. 대체로 속도가 바뀌는 지점의 도로에서 과속이 많이 발생하고 이에 따라 허용 용량 이상으로 차량이 통과하는 것으로 보임. 따라서, 실제 통과 차량의 한계를 얼마나 정할 것인지 정할 필요가 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while idx < raw_df.shape[1] - 1:\n",
    "    idx += 1\n",
    "    original_data = raw_df.iloc[:, idx]\n",
    "    target_data = base_df.iloc[:, idx]\n",
    "\n",
    "    if original_data.isna().sum() == target_data.isna().sum():\n",
    "        continue\n",
    "\n",
    "    not_0_and_na = original_data[original_data != 0]\n",
    "    not_0_and_na = not_0_and_na[not_0_and_na.notna()]\n",
    "    na_target = target_data[not_0_and_na.index]\n",
    "    if na_target.isna().sum() == 0:\n",
    "        continue\n",
    "\n",
    "    print(original_data.name, \"(Origin):\" , original_data.isna().sum())\n",
    "    print(target_data.name, \"(Target):\", target_data.isna().sum())\n",
    "    metadata = raw_metadata_df[raw_metadata_df[\"LINK_ID\"] == original_data.name]\n",
    "    print(metadata)\n",
    "\n",
    "    speed_limit = metadata[\"MAX_SPD\"].values[0]\n",
    "    alpha = 10 * (100 - speed_limit)\n",
    "    if speed_limit > 100:\n",
    "        alpha /= 2\n",
    "    lane_count = metadata[\"LANES\"].values[0]\n",
    "    adjustment_rate = 2.5\n",
    "    original_capacity = (2200 - alpha) * lane_count\n",
    "    capacity = original_capacity * adjustment_rate\n",
    "    print(\"Capacity:\", capacity, f\"({original_capacity} x {adjustment_rate})\")\n",
    "    exceed_capacity_data = target_data[target_data > capacity]\n",
    "    print(exceed_capacity_data if exceed_capacity_data.size > 0 else \"No exceed capacity data\")\n",
    "\n",
    "    compare_fromto_df(original_data, target_data, title=f\"Origin vs Target: {original_data.name}\")\n",
    "    \n",
    "    break\n",
    "\n",
    "print(original_data.name)\n",
    "geo_gdf[geo_gdf[\"LINK_ID\"] == original_data.name].explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 여러 Outlier 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metr.components.metr_imc.outlier import (\n",
    "    OutlierProcessor,\n",
    "    HourlyInSensorZscoreOutlierProcessor,\n",
    "    InSensorZscoreOutlierProcessor,\n",
    "    MADOutlierProcessor,\n",
    "    TrimmedMeanOutlierProcessor,\n",
    "    WinsorizedOutlierProcessor,\n",
    ")\n",
    "from songdo_rnn.preprocessing.outlier import (\n",
    "    get_outlier_removed_data_list,\n",
    "    remove_outliers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_processors: List[OutlierProcessor] = [\n",
    "    HourlyInSensorZscoreOutlierProcessor(),\n",
    "    InSensorZscoreOutlierProcessor(),\n",
    "    WinsorizedOutlierProcessor(),\n",
    "    TrimmedMeanOutlierProcessor(),\n",
    "    MADOutlierProcessor(),\n",
    "]\n",
    "\n",
    "outlier_processors[0].name = \"hzscore\"\n",
    "outlier_processors[1].name = \"zscore\"\n",
    "outlier_processors[2].name = \"winsor\"\n",
    "outlier_processors[3].name = \"trimm\"\n",
    "outlier_processors[4].name = \"mad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_paths = remove_outliers(\n",
    "    data=base_df,\n",
    "    outlier_processors=outlier_processors,\n",
    "    output_dir=OUTLIER_OUTPUT_DIR,\n",
    ")\n",
    "result_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_results = get_outlier_removed_data_list()\n",
    "len(outlier_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
