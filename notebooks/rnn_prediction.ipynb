{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers and Missing Data (Prediction Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from glob import glob\n",
    "from typing import Dict, List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import yaml\n",
    "from lightning import Trainer\n",
    "from lightning.pytorch.callbacks import (\n",
    "    EarlyStopping,\n",
    "    LearningRateMonitor,\n",
    "    ModelCheckpoint,\n",
    ")\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from metr.components import TrafficData\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error\n",
    "from songdo_llm.dataset import TrafficDataModule\n",
    "from songdo_llm.model.lightning.simple_prediction import TrafficVolumePredictionModule\n",
    "from songdo_rnn.utils import symmetric_mean_absolute_percentage_error\n",
    "from tqdm import tqdm\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"AppleGothic\"\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False  # 음수 부호 깨짐 방지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INTERPOLATED_DATA_DIR = \"./output/interpolated\"\n",
    "TARGET_DATA_DIR = os.path.join(INTERPOLATED_DATA_DIR, \"ptest\")\n",
    "PREDICTION_OUTPUT_DIR = \"./output/prediction\"\n",
    "RESULT_DIR = \"./output\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 필요한 데이터 읽기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_list(data_dir: str) -> List[TrafficData]:\n",
    "    data_path_list = glob(os.path.join(data_dir, \"*.h5\"))\n",
    "    return [TrafficData.import_from_hdf(path) for path in data_path_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_prediction = get_data_list(TARGET_DATA_DIR)\n",
    "pred_dfs = [tdata.data for tdata in data_for_prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dfs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_hdf(os.path.join(PREDICTION_OUTPUT_DIR, \"test.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "seq_length: int = 24\n",
    "input_dim: int = 1\n",
    "hidden_dim: int = 32\n",
    "num_layers: int = 1\n",
    "output_dim: int = 1\n",
    "epochs: int = 50\n",
    "batch_size: int = 64\n",
    "\n",
    "learning_rate: float = 0.001\n",
    "lr_step_size: int = 100\n",
    "lr_gamma: float = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습\n",
    "\n",
    "각 보정 모델 별로 그리고 센서별로 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_seed(seed: int):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_output_dir = lambda name, sensor_id: os.path.join(PREDICTION_OUTPUT_DIR, name, sensor_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    training_data: pd.DataFrame,\n",
    "    test_data: pd.DataFrame,\n",
    "    output_dir: str,\n",
    "):\n",
    "    data_module = TrafficDataModule(\n",
    "        training_df=training_data,\n",
    "        test_df=test_data,\n",
    "        seq_length=seq_length,\n",
    "        batch_size=batch_size,\n",
    "        valid_split_datetime=\"2024-06-01 00:00:00\",\n",
    "        strict_scaling=True,    # 임시 해결책. 학습 데이터가 많지 않아 가능한 해법.\n",
    "    )\n",
    "\n",
    "    traffic_model = TrafficVolumePredictionModule(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        output_dim=output_dim,\n",
    "        learning_rate=learning_rate,\n",
    "        lr_step_size=lr_step_size,\n",
    "        lr_gamma=lr_gamma,\n",
    "    )\n",
    "    wandb_logger = WandbLogger(project=\"Songdo_LSTM\", log_model=\"all\")\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        max_epochs=epochs,\n",
    "        accelerator=\"auto\",\n",
    "        devices=\"auto\",\n",
    "        log_every_n_steps=1,\n",
    "        default_root_dir=output_dir,\n",
    "        logger=wandb_logger,\n",
    "        callbacks=[\n",
    "            EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5),\n",
    "            ModelCheckpoint(\n",
    "                dirpath=output_dir,\n",
    "                # filename=\"best-{epoch:02d}-{val_loss:.2f}\",\n",
    "                filename=\"best-{epoch:02d}-{val_loss:.2f}\",\n",
    "                save_top_k=1,\n",
    "                monitor=\"val_loss\",\n",
    "                mode=\"min\",\n",
    "            ),\n",
    "            LearningRateMonitor(logging_interval=\"step\"),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    trainer.fit(traffic_model, data_module)\n",
    "\n",
    "    return data_module, traffic_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_by_model(\n",
    "    data: TrafficDataModule,\n",
    "    model_dir: str,\n",
    "):\n",
    "    checkpoint_files = glob(os.path.join(model_dir, \"best*.ckpt\"))\n",
    "    checkpoint_path = checkpoint_files[0]\n",
    "    print(f\"Using checkpoint: {os.path.basename(checkpoint_path)}\")\n",
    "\n",
    "    traffic_model = TrafficVolumePredictionModule.load_from_checkpoint(\n",
    "        checkpoint_path=checkpoint_path\n",
    "    )\n",
    "    traffic_model.eval()\n",
    "    data_loader = data.predict_dataloader()\n",
    "\n",
    "    # -------------------\n",
    "    # Prediction\n",
    "    # -------------------\n",
    "    test_scaled_true: List[np.ndarray] = []\n",
    "    test_scaled_pred: List[np.ndarray] = []\n",
    "    for idx, item in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "        x: torch.Tensor = item[0]\n",
    "        y: torch.Tensor = item[1]\n",
    "\n",
    "        x_nan_mask = torch.isnan(x.view(x.size(0), -1)).any(dim=1)\n",
    "        y_nan_mask = torch.isnan(y.view(y.size(0), -1)).any(dim=1)\n",
    "        invalid_mask = (\n",
    "            x_nan_mask | y_nan_mask\n",
    "        )  # x 또는 y 둘 중 하나라도 NaN이 있으면 invalid\n",
    "        valid_mask = ~invalid_mask\n",
    "\n",
    "        x_filtered = x[valid_mask]\n",
    "        y_filtered = y[valid_mask]\n",
    "\n",
    "        if x.size(0) != x_filtered.size(0):\n",
    "            print(\n",
    "                f\"[{idx + 1}/{len(data_loader)}] Batch Filtered: {x.size(0)} -> {x_filtered.size(0)}\"\n",
    "            )\n",
    "        if x_filtered.size(0) == 0:\n",
    "            print(f\"[{idx + 1}/{len(data_loader)}] Batch Passed\")\n",
    "            continue\n",
    "\n",
    "        x_filtered = x_filtered.to(traffic_model.device)\n",
    "        y_filtered = y_filtered.to(traffic_model.device)\n",
    "\n",
    "        y_hat: torch.Tensor = traffic_model(x_filtered)\n",
    "\n",
    "        test_scaled_true.append(y_filtered.cpu().detach().numpy())\n",
    "        test_scaled_pred.append(y_hat.cpu().detach().numpy())\n",
    "\n",
    "    if len(test_scaled_true) == 0 or len(test_scaled_pred) == 0:\n",
    "        print(f\"No valid data for sensor\")\n",
    "        return\n",
    "\n",
    "    test_scaled_true_arr = np.concatenate(test_scaled_true, axis=0)\n",
    "    test_scaled_pred_arr = np.concatenate(test_scaled_pred, axis=0)\n",
    "    scaler = data.scaler\n",
    "    test_true_arr = scaler.inverse_transform(test_scaled_true_arr)\n",
    "    test_pred_arr = scaler.inverse_transform(test_scaled_pred_arr)\n",
    "    test_true = test_true_arr.squeeze(1)\n",
    "    test_pred = test_pred_arr.squeeze(1)\n",
    "\n",
    "    return test_true, test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 30\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targ_dirs = glob(os.path.join(TARGET_DATA_DIR, \"*\"))\n",
    "[f\"{idx:>2}: {name}\" for idx, name in enumerate(targ_dirs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dirs = glob(os.path.join(PREDICTION_OUTPUT_DIR, \"*\"))\n",
    "for idx, pred_dir in enumerate(pred_dirs):\n",
    "    metrics = glob(os.path.join(pred_dir, \"*\", \"metrics_*.yaml\"))\n",
    "\n",
    "    print(idx, \"(\", os.path.basename(pred_dir), \"):\", len(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_count = 0\n",
    "\n",
    "for processed_data in data_for_prediction:\n",
    "    name = os.path.basename(processed_data.path)\n",
    "    df = processed_data.data\n",
    "    \n",
    "    target_sensors = random.sample(list(df.columns), min(k, len(df.columns)))\n",
    "    print(f\"Selected sensors: {target_sensors}\")\n",
    "\n",
    "    for sensor_name in target_sensors:\n",
    "        sensor_data = pd.DataFrame({sensor_name: df[sensor_name]})\n",
    "        test_data = pd.DataFrame({sensor_name: test_df[sensor_name]})\n",
    "\n",
    "        output_dir = get_output_dir(name, sensor_name)\n",
    "        if os.path.exists(output_dir) and len(os.listdir(output_dir)) > 0:\n",
    "            print(f\"Skip: {output_dir} already exists\")\n",
    "            continue\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        try:\n",
    "            data_module, _ = train_model(sensor_data, test_data, output_dir)\n",
    "        except AssertionError as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            continue\n",
    "        \n",
    "        result = predict_by_model(data_module, output_dir)\n",
    "        if result is None:\n",
    "            print(f\"Warning: No valid prediction for {sensor_name}\")\n",
    "            continue\n",
    "        test_true, test_pred = result\n",
    "\n",
    "        test_mae = mean_absolute_error(test_true, test_pred)\n",
    "        test_rmse = root_mean_squared_error(test_true, test_pred)\n",
    "        test_smape = symmetric_mean_absolute_percentage_error(test_true, test_pred)\n",
    "\n",
    "        metrics_dict = {\n",
    "            \"MAE\": test_mae,\n",
    "            \"RMSE\": test_rmse,\n",
    "            \"sMAPE\": test_smape,\n",
    "        }\n",
    "\n",
    "        metrics_file_name = f\"metrics_{sensor_name}.yaml\"\n",
    "        yaml_path = os.path.join(output_dir, metrics_file_name)\n",
    "        with open(yaml_path, \"w\") as f:\n",
    "            yaml.safe_dump(metrics_dict, f)\n",
    "        print(f\"Metrics saved to {yaml_path}\")\n",
    "\n",
    "        training_count += 1\n",
    "    \n",
    "    if training_count >= 300:\n",
    "        print(\"Training limit reached. Stopped training for prevent memory problem.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_metrics: Dict[str, Dict[str, float]] = {}\n",
    "for pred_dir in pred_dirs:\n",
    "    metrics = glob(os.path.join(pred_dir, \"*\", \"metrics_*.yaml\"))\n",
    "    \n",
    "    model_name = os.path.basename(pred_dir)\n",
    "    metrics_values = {\n",
    "        \"MAE\": [],\n",
    "        \"RMSE\": [],\n",
    "        \"sMAPE\": [],\n",
    "    }\n",
    "    \n",
    "    for metric_file in metrics:\n",
    "        with open(metric_file, \"r\") as f:\n",
    "            metric = yaml.safe_load(f)\n",
    "            for key in metric.keys():\n",
    "                metrics_values[key].append(metric[key])\n",
    "    \n",
    "    pred_metrics[model_name] = {}\n",
    "    for key in metrics_values.keys():\n",
    "        pred_metrics[model_name][key] = np.mean(metrics_values[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(pred_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_metrics: Dict[str, Dict[str, float]] = {}\n",
    "for pred_dir in pred_dirs:\n",
    "    if not os.path.isdir(pred_dir):\n",
    "        continue\n",
    "    model_name = os.path.basename(pred_dir).split(\".\")[0]\n",
    "    metric_paths = glob(os.path.join(pred_dir, \"*\", \"metrics_*.yaml\"))\n",
    "    for metric_path in metric_paths:\n",
    "        sensor_name = os.path.basename(os.path.dirname(metric_path))\n",
    "\n",
    "        with open(metric_path, \"r\") as f:\n",
    "            metric: Dict[str, float] = yaml.safe_load(f)\n",
    "            for key in metric.keys():\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메트릭 유형별로 별도의 딕셔너리 초기화\n",
    "metrics_dict = {'MAE': {}, 'RMSE': {}, 'sMAPE': {}}\n",
    "\n",
    "for pred_dir in pred_dirs:\n",
    "    if not os.path.isdir(pred_dir):\n",
    "        continue\n",
    "    model_name = os.path.basename(pred_dir).split(\".\")[0]\n",
    "    \n",
    "    # 각 메트릭 유형에 대해 모델별 딕셔너리 초기화\n",
    "    for metric_type in metrics_dict.keys():\n",
    "        metrics_dict[metric_type][model_name] = {}\n",
    "    \n",
    "    metric_paths = glob(os.path.join(pred_dir, \"*\", \"metrics_*.yaml\"))\n",
    "    for metric_path in metric_paths:\n",
    "        sensor_name = os.path.basename(os.path.dirname(metric_path))\n",
    "\n",
    "        with open(metric_path, \"r\") as f:\n",
    "            metric = yaml.safe_load(f)\n",
    "            \n",
    "            # 각 메트릭 유형마다 값 저장\n",
    "            for metric_type in metrics_dict.keys():\n",
    "                metrics_dict[metric_type][model_name][sensor_name] = metric[metric_type]\n",
    "\n",
    "# 각 메트릭 유형별로 DataFrame 생성 (인덱스가 model_name, 컬럼이 sensor_name)\n",
    "mae_df = pd.DataFrame(metrics_dict['MAE']).T\n",
    "rmse_df = pd.DataFrame(metrics_dict['RMSE']).T\n",
    "smape_df = pd.DataFrame(metrics_dict['sMAPE']).T\n",
    "\n",
    "# 결과 확인\n",
    "print(\"MAE DataFrame 형태:\", mae_df.shape)\n",
    "print(\"RMSE DataFrame 형태:\", rmse_df.shape)\n",
    "print(\"sMAPE DataFrame 형태:\", smape_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_df.to_excel(os.path.join(RESULT_DIR, \"prep_mae.xlsx\"))\n",
    "rmse_df.to_excel(os.path.join(RESULT_DIR, \"prep_rmse.xlsx\"))\n",
    "smape_df.to_excel(os.path.join(RESULT_DIR, \"prep_smape.xlsx\"))\n",
    "mae_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
