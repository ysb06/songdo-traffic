{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28756895",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from metr.components.metr_imc.traffic_data import TrafficData\n",
    "from metr.utils import PathConfig\n",
    "from numpy.lib.npyio import NpzFile\n",
    "from scipy.stats import norm\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from statsmodels.tsa.stattools import acf, adfuller\n",
    "from scipy.stats import zscore\n",
    "from scipy.stats import entropy, norm\n",
    "import pycatch22\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10f8fd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_CONF = PathConfig.from_yaml(\"../config.yaml\")\n",
    "FILTERED_PATH_CONF = PathConfig.from_yaml(\"../config_brits.yaml\")\n",
    "# 체크포인트 경로 설정 (DCRNN)\n",
    "CHECKPOINT_PATH = \"../traffic_imc/output/dcrnn/BRITS/model.ckpt\"\n",
    "if not os.path.exists(CHECKPOINT_PATH):\n",
    "    raise FileNotFoundError(f\"Checkpoint path {CHECKPOINT_PATH} does not exist.\")\n",
    "\n",
    "TRAFFIC_DATA_PATH = PATH_CONF.metr_imc_path\n",
    "NODELINK_SHAPE_PATH = PATH_CONF.nodelink_link_path\n",
    "ADJ_MX_PATH = PATH_CONF.adj_mx_path\n",
    "METADATA_PATH = PATH_CONF.metadata_path\n",
    "\n",
    "FILTERED_DATA_PATH = FILTERED_PATH_CONF.metr_imc_path\n",
    "FILTERED_NODELINK_SHAPE_PATH = FILTERED_PATH_CONF.metr_shapefile_path\n",
    "FILTERED_ADJ_MX_PATH = FILTERED_PATH_CONF.adj_mx_path\n",
    "FILTERED_METADATA_PATH = FILTERED_PATH_CONF.metadata_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e622177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up visualization parameters\n",
    "plt.rcParams[\"font.family\"] = \"AppleGothic\"  # Use AppleGothic for better font rendering\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False  # Prevent negative sign rendering issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb88b9b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1630020000</th>\n",
       "      <th>1630168900</th>\n",
       "      <th>1640010500</th>\n",
       "      <th>1640021100</th>\n",
       "      <th>1680010502</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-01 00:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01 01:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01 02:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01 03:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01 04:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-15 19:00:00</th>\n",
       "      <td>264.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-15 20:00:00</th>\n",
       "      <td>175.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-15 21:00:00</th>\n",
       "      <td>129.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-15 22:00:00</th>\n",
       "      <td>85.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-15 23:00:00</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26664 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     1630020000  1630168900  1640010500  1640021100  \\\n",
       "2023-01-01 00:00:00         NaN         NaN         NaN         NaN   \n",
       "2023-01-01 01:00:00         NaN         NaN         NaN         NaN   \n",
       "2023-01-01 02:00:00         NaN         NaN         NaN         NaN   \n",
       "2023-01-01 03:00:00         NaN         NaN         NaN         NaN   \n",
       "2023-01-01 04:00:00         NaN         NaN         NaN         NaN   \n",
       "...                         ...         ...         ...         ...   \n",
       "2026-01-15 19:00:00       264.0         9.0         0.0         0.0   \n",
       "2026-01-15 20:00:00       175.0         5.0         0.0         0.0   \n",
       "2026-01-15 21:00:00       129.0         3.0         0.0         0.0   \n",
       "2026-01-15 22:00:00        85.0         3.0         0.0         0.0   \n",
       "2026-01-15 23:00:00        42.0         0.0         0.0         0.0   \n",
       "\n",
       "                     1680010502  \n",
       "2023-01-01 00:00:00         NaN  \n",
       "2023-01-01 01:00:00         NaN  \n",
       "2023-01-01 02:00:00         NaN  \n",
       "2023-01-01 03:00:00         NaN  \n",
       "2023-01-01 04:00:00         NaN  \n",
       "...                         ...  \n",
       "2026-01-15 19:00:00         NaN  \n",
       "2026-01-15 20:00:00         NaN  \n",
       "2026-01-15 21:00:00         NaN  \n",
       "2026-01-15 22:00:00         NaN  \n",
       "2026-01-15 23:00:00         NaN  \n",
       "\n",
       "[26664 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = TrafficData.import_from_hdf(TRAFFIC_DATA_PATH)\n",
    "df = raw.data\n",
    "df.iloc[:, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ccb73dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1630020000</th>\n",
       "      <th>1630168900</th>\n",
       "      <th>1640010500</th>\n",
       "      <th>1640021100</th>\n",
       "      <th>1680055400</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-26 00:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.779705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-26 01:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.620499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-26 02:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.326149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-26 03:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.690292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-26 04:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.243927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     1630020000  1630168900  1640010500  1640021100  \\\n",
       "2023-01-26 00:00:00         0.0         0.0       204.0         0.0   \n",
       "2023-01-26 01:00:00         0.0         0.0       137.0         0.0   \n",
       "2023-01-26 02:00:00         0.0         0.0        83.0         0.0   \n",
       "2023-01-26 03:00:00         0.0         0.0        57.0         0.0   \n",
       "2023-01-26 04:00:00         0.0         0.0       136.0         0.0   \n",
       "\n",
       "                     1680055400  \n",
       "2023-01-26 00:00:00   10.779705  \n",
       "2023-01-26 01:00:00    1.620499  \n",
       "2023-01-26 02:00:00    0.326149  \n",
       "2023-01-26 03:00:00    2.690292  \n",
       "2023-01-26 04:00:00   -0.243927  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_raw = TrafficData.import_from_hdf(FILTERED_DATA_PATH)\n",
    "imputed_df = imputed_raw.data\n",
    "imputed_df.iloc[:, :5].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36b6bebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LINK_ID</th>\n",
       "      <th>ROAD_NAME</th>\n",
       "      <th>LANES</th>\n",
       "      <th>ROAD_RANK</th>\n",
       "      <th>ROAD_TYPE</th>\n",
       "      <th>MAX_SPD</th>\n",
       "      <th>REST_VEH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1630020000</td>\n",
       "      <td>한나루로</td>\n",
       "      <td>2</td>\n",
       "      <td>104</td>\n",
       "      <td>000</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1630168900</td>\n",
       "      <td>석정로</td>\n",
       "      <td>2</td>\n",
       "      <td>104</td>\n",
       "      <td>000</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1640010500</td>\n",
       "      <td>경원대로</td>\n",
       "      <td>5</td>\n",
       "      <td>104</td>\n",
       "      <td>000</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1640021100</td>\n",
       "      <td>먼우금로</td>\n",
       "      <td>3</td>\n",
       "      <td>104</td>\n",
       "      <td>000</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1680055400</td>\n",
       "      <td>봉수대로</td>\n",
       "      <td>3</td>\n",
       "      <td>104</td>\n",
       "      <td>000</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15935</th>\n",
       "      <td>1650278500</td>\n",
       "      <td>남동대로</td>\n",
       "      <td>4</td>\n",
       "      <td>104</td>\n",
       "      <td>000</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15936</th>\n",
       "      <td>1650278600</td>\n",
       "      <td>남동대로</td>\n",
       "      <td>4</td>\n",
       "      <td>104</td>\n",
       "      <td>000</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15972</th>\n",
       "      <td>1680257100</td>\n",
       "      <td>중봉대로</td>\n",
       "      <td>2</td>\n",
       "      <td>104</td>\n",
       "      <td>000</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15973</th>\n",
       "      <td>1680257900</td>\n",
       "      <td>중봉대로</td>\n",
       "      <td>2</td>\n",
       "      <td>104</td>\n",
       "      <td>000</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15974</th>\n",
       "      <td>1680258100</td>\n",
       "      <td>중봉대로</td>\n",
       "      <td>2</td>\n",
       "      <td>104</td>\n",
       "      <td>000</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2015 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          LINK_ID ROAD_NAME  LANES ROAD_RANK ROAD_TYPE  MAX_SPD REST_VEH\n",
       "15     1630020000      한나루로      2       104       000       50        0\n",
       "17     1630168900       석정로      2       104       000       50        0\n",
       "18     1640010500      경원대로      5       104       000       60        0\n",
       "21     1640021100      먼우금로      3       104       000       30        0\n",
       "50     1680055400      봉수대로      3       104       000       60        0\n",
       "...           ...       ...    ...       ...       ...      ...      ...\n",
       "15935  1650278500      남동대로      4       104       000       50        0\n",
       "15936  1650278600      남동대로      4       104       000       50        0\n",
       "15972  1680257100      중봉대로      2       104       000       60        0\n",
       "15973  1680257900      중봉대로      2       104       000       60        0\n",
       "15974  1680258100      중봉대로      2       104       000       60        0\n",
       "\n",
       "[2015 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_raw = pd.read_hdf(FILTERED_METADATA_PATH)\n",
    "metadata_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46d562b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ArrowStringArray>\n",
       "['104', '107', '101', '103', '105', '106']\n",
       "Length: 6, dtype: str"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_raw[\"ROAD_RANK\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4a6a0e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116      1630167000\n",
       "2221     1630174501\n",
       "2223     1630174601\n",
       "2224     1630174701\n",
       "2225     1630174801\n",
       "2226     1630174901\n",
       "2227     1630175001\n",
       "2228     1630175101\n",
       "2229     1630175201\n",
       "2230     1630175301\n",
       "2231     1630175401\n",
       "3719     1610079200\n",
       "3720     1610079300\n",
       "4546     1610080400\n",
       "4547     1610080600\n",
       "7213     1640054700\n",
       "8246     1640316500\n",
       "8278     1640320200\n",
       "8279     1640320300\n",
       "8281     1650004100\n",
       "8282     1640320400\n",
       "8298     1650003901\n",
       "8310     1650004200\n",
       "8311     1650004300\n",
       "8312     1650004400\n",
       "8313     1650004500\n",
       "8315     1650004600\n",
       "8316     1650004900\n",
       "8317     1650005000\n",
       "9241     1650314500\n",
       "9242     1650314900\n",
       "9489     1650350800\n",
       "9490     1650350900\n",
       "9524     1660003701\n",
       "9525     1660003702\n",
       "9526     1660003801\n",
       "9528     1660003802\n",
       "9529     1660003900\n",
       "9530     1660004000\n",
       "10140    1663132600\n",
       "10331    1670003500\n",
       "10334    1670002500\n",
       "10339    1670002800\n",
       "10344    1670003400\n",
       "10353    1670004000\n",
       "10363    1670004100\n",
       "10997    1670222800\n",
       "10999    1670222900\n",
       "11055    1680008501\n",
       "11056    1680008503\n",
       "11057    1680008601\n",
       "11058    1680008603\n",
       "13820    1680497500\n",
       "13821    1680497600\n",
       "15207    1663132500\n",
       "Name: LINK_ID, dtype: str"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highways_info = metadata_raw[metadata_raw['ROAD_RANK'] == '101']\n",
    "highways_list = highways_info['LINK_ID']\n",
    "highways_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cf610e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15       1630020000\n",
       "17       1630168900\n",
       "18       1640010500\n",
       "21       1640021100\n",
       "50       1680055400\n",
       "            ...    \n",
       "15935    1650278500\n",
       "15936    1650278600\n",
       "15972    1680257100\n",
       "15973    1680257900\n",
       "15974    1680258100\n",
       "Name: LINK_ID, Length: 1960, dtype: str"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_road_info = metadata_raw[metadata_raw['ROAD_RANK'] != '101']\n",
    "normal_road_list = normal_road_info['LINK_ID']\n",
    "normal_road_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b4fca2",
   "metadata": {},
   "source": [
    "## DCRNN 모델 고속도로 센서 평가\n",
    "\n",
    "학습된 DCRNN 모델을 불러와서 고속도로(ROAD_RANK='101') 센서에 대해서만 MAE, RMSE, MAPE를 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b93619eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sbyim/Workspace/Python/songdo-traffic/notebooks/.venv/lib/python3.11/site-packages/torchmetrics/utilities/imports.py:22: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import DistributionNotFound, get_distribution\n",
      "/Users/sbyim/Workspace/Python/songdo-traffic/notebooks/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "from metr.components.adj_mx import AdjacencyMatrix\n",
    "from metr.datasets.dcrnn import DCRNNSplitDataModule\n",
    "from metr_val.models.dcrnn import DCRNNLightningModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d146d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# 디바이스 설정\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else \\\n",
    "         torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50123c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vertices (sensors): 2015\n",
      "Sensor IDs sample: ['1630020000', '1630168900', '1640010500', '1640021100', '1680055400']\n",
      "Adjacency matrix shape: (2015, 2015)\n"
     ]
    }
   ],
   "source": [
    "# Adjacency Matrix 로드\n",
    "adj_mx_obj = AdjacencyMatrix.import_from_pickle(FILTERED_ADJ_MX_PATH)\n",
    "adj_mx = adj_mx_obj.adj_mx\n",
    "sensor_ids = adj_mx_obj.sensor_ids  # 순서가 지정된 센서 ID 리스트\n",
    "n_vertex = adj_mx.shape[0]\n",
    "\n",
    "print(f\"Number of vertices (sensors): {n_vertex}\")\n",
    "print(f\"Sensor IDs sample: {sensor_ids[:5]}\")\n",
    "print(f\"Adjacency matrix shape: {adj_mx.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdf34e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data split - Train: 19968 rows (80%), Val: 4992 rows (20%)\n",
      "Test data loaded: 1104 rows\n",
      "Test dataset size: 1081\n",
      "Input dimension: 2\n",
      "Output dimension: 1\n"
     ]
    }
   ],
   "source": [
    "# 데이터 모듈 설정 (DCRNN용)\n",
    "# DCRNN 하이퍼파라미터 (dcrnn.py 참조)\n",
    "SEQ_LEN = 12\n",
    "HORIZON = 12\n",
    "ADD_TIME_IN_DAY = True\n",
    "ADD_DAY_IN_WEEK = False\n",
    "\n",
    "data_module = DCRNNSplitDataModule(\n",
    "    training_data_path=FILTERED_PATH_CONF.metr_imc_training_path,\n",
    "    test_data_path=FILTERED_PATH_CONF.metr_imc_test_path,\n",
    "    test_missing_path=FILTERED_PATH_CONF.metr_imc_test_missing_path,\n",
    "    adj_mx_path=FILTERED_PATH_CONF.adj_mx_path,\n",
    "    seq_len=SEQ_LEN,\n",
    "    horizon=HORIZON,\n",
    "    batch_size=64,\n",
    "    num_workers=0,  # Notebook에서는 0 권장\n",
    "    shuffle_training=False,\n",
    "    train_val_split=0.8,\n",
    "    add_time_in_day=ADD_TIME_IN_DAY,\n",
    "    add_day_in_week=ADD_DAY_IN_WEEK,\n",
    ")\n",
    "\n",
    "# fit 단계에서 scaler 준비\n",
    "data_module.setup(\"fit\")\n",
    "scaler = data_module.scaler\n",
    "\n",
    "# test 단계 설정\n",
    "data_module.setup(\"test\")\n",
    "print(f\"Test dataset size: {len(data_module.test_dataset)}\")\n",
    "print(f\"Input dimension: {data_module.input_dim}\")\n",
    "print(f\"Output dimension: {data_module.output_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a80f4a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sbyim/Workspace/Python/songdo-traffic/notebooks/.venv/lib/python3.11/site-packages/lightning/pytorch/core/saving.py:197: Found keys that are not in the model state dict but in the checkpoint: ['model.encoder_model.dcgru_layers.0.gconv_weight_(330, 128)', 'model.encoder_model.dcgru_layers.0.gconv_biases_128', 'model.encoder_model.dcgru_layers.0.gconv_weight_(330, 64)', 'model.encoder_model.dcgru_layers.0.gconv_biases_64', 'model.encoder_model.dcgru_layers.1.gconv_weight_(640, 128)', 'model.encoder_model.dcgru_layers.1.gconv_biases_128', 'model.encoder_model.dcgru_layers.1.gconv_weight_(640, 64)', 'model.encoder_model.dcgru_layers.1.gconv_biases_64', 'model.decoder_model.dcgru_layers.0.gconv_weight_(325, 128)', 'model.decoder_model.dcgru_layers.0.gconv_biases_128', 'model.decoder_model.dcgru_layers.0.gconv_weight_(325, 64)', 'model.decoder_model.dcgru_layers.0.gconv_biases_64', 'model.decoder_model.dcgru_layers.1.gconv_weight_(640, 128)', 'model.decoder_model.dcgru_layers.1.gconv_biases_128', 'model.decoder_model.dcgru_layers.1.gconv_weight_(640, 64)', 'model.decoder_model.dcgru_layers.1.gconv_biases_64']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from ../traffic_imc/output/dcrnn/BRITS/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "# 체크포인트에서 DCRNN 모델 로드\n",
    "# DCRNN은 첫 forward pass 시 동적으로 파라미터를 생성하므로 특별한 로딩 과정 필요\n",
    "\n",
    "# 1. 기본 모델 생성 (동적 파라미터 없이)\n",
    "model = DCRNNLightningModule.load_from_checkpoint(\n",
    "    CHECKPOINT_PATH,\n",
    "    adj_mx=adj_mx,\n",
    "    scaler=scaler,\n",
    "    map_location=\"cpu\",\n",
    "    strict=False,  # 동적 파라미터 로딩을 위해 필요\n",
    ")\n",
    "\n",
    "# 2. 더미 forward pass를 수행하여 동적 파라미터 생성\n",
    "# 테스트 데이터의 첫 배치를 가져와서 forward pass 수행\n",
    "model.eval()  # eval 모드에서는 curriculum learning이 사용되지 않음\n",
    "with torch.no_grad():\n",
    "    dummy_batch = next(iter(data_module.test_dataloader()))\n",
    "    dummy_x = dummy_batch[0]  # (seq_len, batch_size, num_nodes * input_dim)\n",
    "    _ = model(dummy_x)  # 이 과정에서 DCGRUCell의 동적 파라미터가 생성됨\n",
    "\n",
    "# 3. 이제 동적 파라미터가 생성되었으므로 state_dict를 다시 로드\n",
    "checkpoint = torch.load(CHECKPOINT_PATH, map_location=\"cpu\", weights_only=False)\n",
    "model.load_state_dict(checkpoint[\"state_dict\"], strict=True)  # strict=True로 변경하여 확인\n",
    "\n",
    "# 모델 전체를 디바이스로 이동\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print(f\"Model loaded from {CHECKPOINT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7a1164f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sensors: 2015\n",
      "Highway sensors: 55\n",
      "Normal road sensors: 1960\n"
     ]
    }
   ],
   "source": [
    "# 고속도로 및 일반도로 센서의 인덱스 찾기 (sensor_id_to_idx 사용)\n",
    "sensor_id_to_idx = adj_mx_obj.sensor_id_to_idx\n",
    "\n",
    "# 고속도로 센서의 인덱스 추출 (명시적 매핑 사용)\n",
    "highway_indices = [\n",
    "    sensor_id_to_idx[str(sid)] \n",
    "    for sid in highways_list \n",
    "    if str(sid) in sensor_id_to_idx\n",
    "]\n",
    "\n",
    "# 일반도로 센서의 인덱스 추출\n",
    "normal_road_indices = [\n",
    "    sensor_id_to_idx[str(sid)] \n",
    "    for sid in normal_road_list \n",
    "    if str(sid) in sensor_id_to_idx\n",
    "]\n",
    "\n",
    "print(f\"Total sensors: {len(sensor_id_to_idx)}\")\n",
    "print(f\"Highway sensors: {len(highway_indices)}\")\n",
    "print(f\"Normal road sensors: {len(normal_road_indices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "305e9856",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [26:36<00:00, 93.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions shape: (1081, 12, 2015)\n",
      "Ground truth shape: (1081, 12, 2015)\n",
      "Missing mask shape: (1081, 12, 2015)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터에서 예측 수행\n",
    "# DCRNN 입출력 형태:\n",
    "# x: (seq_len, batch_size, num_nodes * input_dim)\n",
    "# y: (horizon, batch_size, num_nodes * output_dim)\n",
    "# y_hat: (horizon, batch_size, num_nodes * output_dim)\n",
    "\n",
    "test_loader = data_module.test_dataloader()\n",
    "\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "all_is_missing = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):\n",
    "        x, y, missing = batch\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        # 모델 예측 (DCRNN forward)\n",
    "        y_hat = model(x)\n",
    "        \n",
    "        # DCRNN 출력 형태: (horizon, batch, num_nodes * output_dim)\n",
    "        # -> (batch, horizon, num_nodes) 로 변환\n",
    "        batch_size = y.shape[1]\n",
    "        num_nodes = n_vertex\n",
    "        \n",
    "        y_reshaped = y.permute(1, 0, 2).reshape(batch_size, HORIZON, num_nodes)\n",
    "        y_hat_reshaped = y_hat.permute(1, 0, 2).reshape(batch_size, HORIZON, num_nodes)\n",
    "        missing_reshaped = missing.permute(1, 0, 2)  # (batch, horizon, num_nodes)\n",
    "        \n",
    "        all_y_true.append(y_reshaped.cpu().numpy())\n",
    "        all_y_pred.append(y_hat_reshaped.cpu().numpy())\n",
    "        all_is_missing.append(missing_reshaped.cpu().numpy())\n",
    "\n",
    "# 배열 연결: (total_samples, horizon, num_nodes)\n",
    "y_true = np.concatenate(all_y_true, axis=0)\n",
    "y_pred = np.concatenate(all_y_pred, axis=0)\n",
    "is_missing = np.concatenate(all_is_missing, axis=0)\n",
    "\n",
    "print(f\"Predictions shape: {y_pred.shape}\")\n",
    "print(f\"Ground truth shape: {y_true.shape}\")\n",
    "print(f\"Missing mask shape: {is_missing.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "852427fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 값 범위 확인 (Scaled) ===\n",
      "y_true range: [-2.4107, 13.8111], mean: -0.0719\n",
      "y_pred range: [-1.4805, 12.0856], mean: -0.0512\n",
      "\n",
      "=== 값 범위 확인 (Unscaled) ===\n",
      "y_true_unscaled range: [-592.2729, 4617.8955], mean: 158.9160\n",
      "y_pred_unscaled range: [-293.5198, 4063.6907], mean: 165.5388\n",
      "\n",
      "=== Scaler 파라미터 ===\n",
      "Scaler mean: 181.9943\n",
      "Scaler scale (std): 321.1833\n",
      "\n",
      "=== 체크포인트의 Scaler ===\n",
      "Scaler가 hyper_parameters에 저장되어 있지 않습니다.\n",
      "\n",
      "=== 모델의 Scaler ===\n",
      "Model scaler mean: 181.9943\n",
      "Model scaler scale: 321.1833\n"
     ]
    }
   ],
   "source": [
    "# 디버깅: y_true와 y_pred의 범위 확인\n",
    "print(\"=== 값 범위 확인 (Scaled) ===\")\n",
    "print(f\"y_true range: [{y_true.min():.4f}, {y_true.max():.4f}], mean: {y_true.mean():.4f}\")\n",
    "print(f\"y_pred range: [{y_pred.min():.4f}, {y_pred.max():.4f}], mean: {y_pred.mean():.4f}\")\n",
    "\n",
    "# Inverse transform 후 값 확인\n",
    "y_true_unscaled_debug = scaler.inverse_transform(y_true.reshape(-1, 1)).flatten()\n",
    "y_pred_unscaled_debug = scaler.inverse_transform(y_pred.reshape(-1, 1)).flatten()\n",
    "\n",
    "print(\"\\n=== 값 범위 확인 (Unscaled) ===\")\n",
    "print(f\"y_true_unscaled range: [{y_true_unscaled_debug.min():.4f}, {y_true_unscaled_debug.max():.4f}], mean: {y_true_unscaled_debug.mean():.4f}\")\n",
    "print(f\"y_pred_unscaled range: [{y_pred_unscaled_debug.min():.4f}, {y_pred_unscaled_debug.max():.4f}], mean: {y_pred_unscaled_debug.mean():.4f}\")\n",
    "\n",
    "# Scaler 파라미터 확인\n",
    "print(\"\\n=== Scaler 파라미터 ===\")\n",
    "print(f\"Scaler mean: {scaler.mean_[0]:.4f}\")\n",
    "print(f\"Scaler scale (std): {scaler.scale_[0]:.4f}\")\n",
    "\n",
    "# 체크포인트에 저장된 scaler와 비교\n",
    "if 'scaler' in checkpoint.get('hyper_parameters', {}):\n",
    "    print(\"\\n=== 체크포인트의 Scaler ===\")\n",
    "    print(\"Scaler가 hyper_parameters에 저장되어 있습니다.\")\n",
    "else:\n",
    "    print(\"\\n=== 체크포인트의 Scaler ===\")\n",
    "    print(\"Scaler가 hyper_parameters에 저장되어 있지 않습니다.\")\n",
    "    \n",
    "# 모델의 scaler 확인\n",
    "print(f\"\\n=== 모델의 Scaler ===\")\n",
    "if model.scaler is not None:\n",
    "    print(f\"Model scaler mean: {model.scaler.mean_[0]:.4f}\")\n",
    "    print(f\"Model scaler scale: {model.scaler.scale_[0]:.4f}\")\n",
    "else:\n",
    "    print(\"Model에 scaler가 없습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e11f67b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highway predictions shape: (1081, 12, 55)\n",
      "\n",
      "=== Highway Sensor Statistics ===\n",
      "Total points: 713460\n",
      "Valid (original) points: 448932 (62.9%)\n",
      "Interpolated points (excluded): 264528 (37.1%)\n"
     ]
    }
   ],
   "source": [
    "# 고속도로 센서만 필터링 (shape: total_samples, horizon, num_highway_sensors)\n",
    "y_true_highway = y_true[:, :, highway_indices]\n",
    "y_pred_highway = y_pred[:, :, highway_indices]\n",
    "is_missing_highway = is_missing[:, :, highway_indices]\n",
    "\n",
    "print(f\"Highway predictions shape: {y_pred_highway.shape}\")\n",
    "\n",
    "# Flatten\n",
    "y_true_flat = y_true_highway.flatten()\n",
    "y_pred_flat = y_pred_highway.flatten()\n",
    "is_missing_flat = is_missing_highway.flatten()\n",
    "\n",
    "# Valid mask (보간되지 않은 원본 데이터만)\n",
    "valid_mask = ~is_missing_flat\n",
    "\n",
    "total_points = len(y_true_flat)\n",
    "valid_points = valid_mask.sum()\n",
    "interpolated_points = total_points - valid_points\n",
    "\n",
    "print(f\"\\n=== Highway Sensor Statistics ===\")\n",
    "print(f\"Total points: {total_points}\")\n",
    "print(f\"Valid (original) points: {valid_points} ({valid_points/total_points*100:.1f}%)\")\n",
    "print(f\"Interpolated points (excluded): {interpolated_points} ({interpolated_points/total_points*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d89e0d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Highway Sensors - Scaled Metrics (Excluding Interpolated) ===\n",
      "MAE:   0.5104\n",
      "RMSE:  0.7509\n",
      "MAPE:  1445.43%\n",
      "sMAPE: 59.09%\n"
     ]
    }
   ],
   "source": [
    "# sMAPE 계산 함수\n",
    "def smape(y_true, y_pred):\n",
    "    \"\"\"Symmetric Mean Absolute Percentage Error (sMAPE)\"\"\"\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "    nonzero_denom = denominator != 0\n",
    "    if not nonzero_denom.any():\n",
    "        return 0.0\n",
    "    return np.mean(np.abs(y_true[nonzero_denom] - y_pred[nonzero_denom]) / denominator[nonzero_denom]) * 100\n",
    "\n",
    "# Scaled 메트릭 계산 (보간되지 않은 데이터만)\n",
    "y_true_valid = y_true_flat[valid_mask]\n",
    "y_pred_valid = y_pred_flat[valid_mask]\n",
    "\n",
    "mae_scaled = mean_absolute_error(y_true_valid, y_pred_valid)\n",
    "rmse_scaled = np.sqrt(mean_squared_error(y_true_valid, y_pred_valid))\n",
    "\n",
    "# MAPE (0으로 나누기 방지)\n",
    "nonzero_mask = y_true_valid != 0\n",
    "mape_scaled = np.mean(np.abs(\n",
    "    (y_true_valid[nonzero_mask] - y_pred_valid[nonzero_mask]) / y_true_valid[nonzero_mask]\n",
    ")) * 100 if nonzero_mask.any() else 0.0\n",
    "\n",
    "# sMAPE\n",
    "smape_scaled = smape(y_true_valid, y_pred_valid)\n",
    "\n",
    "print(f\"\\n=== Highway Sensors - Scaled Metrics (Excluding Interpolated) ===\")\n",
    "print(f\"MAE:   {mae_scaled:.4f}\")\n",
    "print(f\"RMSE:  {rmse_scaled:.4f}\")\n",
    "print(f\"MAPE:  {mape_scaled:.2f}%\")\n",
    "print(f\"sMAPE: {smape_scaled:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eef044c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Highway Sensors - Original Scale Metrics (Excluding Interpolated) ===\n",
      "MAE:   163.9389 vehicles/hour\n",
      "RMSE:  241.1818 vehicles/hour\n",
      "MAPE:  56396700.00%\n",
      "sMAPE: 40.61%\n"
     ]
    }
   ],
   "source": [
    "# Unscaled (원본 스케일) 메트릭 계산\n",
    "def inverse_transform(data, scaler):\n",
    "    \"\"\"Inverse transform scaled data back to original scale.\"\"\"\n",
    "    original_shape = data.shape\n",
    "    flat_data = data.reshape(-1, 1)\n",
    "    unscaled = scaler.inverse_transform(flat_data)\n",
    "    return unscaled.reshape(original_shape)\n",
    "\n",
    "# 원본 스케일로 변환 (shape: total_samples, horizon, num_highway_sensors)\n",
    "y_true_unscaled = inverse_transform(y_true_highway, scaler)\n",
    "y_pred_unscaled = inverse_transform(y_pred_highway, scaler)\n",
    "\n",
    "# Flatten 및 valid mask 적용\n",
    "y_true_unscaled_flat = y_true_unscaled.flatten()\n",
    "y_pred_unscaled_flat = y_pred_unscaled.flatten()\n",
    "y_true_unscaled_valid = y_true_unscaled_flat[valid_mask]\n",
    "y_pred_unscaled_valid = y_pred_unscaled_flat[valid_mask]\n",
    "\n",
    "# Unscaled 메트릭 계산\n",
    "mae_unscaled = mean_absolute_error(y_true_unscaled_valid, y_pred_unscaled_valid)\n",
    "rmse_unscaled = np.sqrt(mean_squared_error(y_true_unscaled_valid, y_pred_unscaled_valid))\n",
    "\n",
    "# MAPE (0으로 나누기 방지)\n",
    "nonzero_mask_unscaled = y_true_unscaled_valid != 0\n",
    "mape_unscaled = np.mean(np.abs(\n",
    "    (y_true_unscaled_valid[nonzero_mask_unscaled] - y_pred_unscaled_valid[nonzero_mask_unscaled]) \n",
    "    / y_true_unscaled_valid[nonzero_mask_unscaled]\n",
    ")) * 100 if nonzero_mask_unscaled.any() else 0.0\n",
    "\n",
    "# sMAPE\n",
    "smape_unscaled = smape(y_true_unscaled_valid, y_pred_unscaled_valid)\n",
    "\n",
    "print(f\"\\n=== Highway Sensors - Original Scale Metrics (Excluding Interpolated) ===\")\n",
    "print(f\"MAE:   {mae_unscaled:.4f} vehicles/hour\")\n",
    "print(f\"RMSE:  {rmse_unscaled:.4f} vehicles/hour\")\n",
    "print(f\"MAPE:  {mape_unscaled:.2f}%\")\n",
    "print(f\"sMAPE: {smape_unscaled:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47d81e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================================\n",
      "DCRNN Performance Comparison (Original Scale)\n",
      "===========================================================================\n",
      "\n",
      "Metric         All Sensors         Highway     Normal Road\n",
      "---------------------------------------------------------------------------\n",
      "MAE                53.1699        163.9389         50.9744\n",
      "RMSE               99.3116        241.1818         94.3681\n",
      "MAPE (%)       35087600.00     56396700.00     34665237.50\n",
      "sMAPE (%)            87.30           40.61           88.22\n",
      "===========================================================================\n",
      "\n",
      "=== Data Points Summary ===\n",
      "All sensors valid points: 23,098,614\n",
      "Highway valid points: 448,932\n",
      "Normal road valid points: 22,649,682\n"
     ]
    }
   ],
   "source": [
    "# 전체 / 고속도로 / 일반도로 비교\n",
    "\n",
    "# === 전체 센서 === (shape: total_samples, horizon, num_nodes)\n",
    "y_true_all_flat = y_true.flatten()\n",
    "y_pred_all_flat = y_pred.flatten()\n",
    "is_missing_all_flat = is_missing.flatten()\n",
    "valid_mask_all = ~is_missing_all_flat\n",
    "\n",
    "y_true_all_unscaled = inverse_transform(y_true, scaler).flatten()\n",
    "y_pred_all_unscaled = inverse_transform(y_pred, scaler).flatten()\n",
    "y_true_all_valid = y_true_all_unscaled[valid_mask_all]\n",
    "y_pred_all_valid = y_pred_all_unscaled[valid_mask_all]\n",
    "\n",
    "mae_all = mean_absolute_error(y_true_all_valid, y_pred_all_valid)\n",
    "rmse_all = np.sqrt(mean_squared_error(y_true_all_valid, y_pred_all_valid))\n",
    "nonzero_all = y_true_all_valid != 0\n",
    "mape_all = np.mean(np.abs(\n",
    "    (y_true_all_valid[nonzero_all] - y_pred_all_valid[nonzero_all]) / y_true_all_valid[nonzero_all]\n",
    ")) * 100 if nonzero_all.any() else 0.0\n",
    "smape_all = smape(y_true_all_valid, y_pred_all_valid)\n",
    "\n",
    "# === 일반도로 센서 === (shape: total_samples, horizon, num_normal_sensors)\n",
    "y_true_normal = y_true[:, :, normal_road_indices]\n",
    "y_pred_normal = y_pred[:, :, normal_road_indices]\n",
    "is_missing_normal = is_missing[:, :, normal_road_indices]\n",
    "\n",
    "y_true_normal_flat = y_true_normal.flatten()\n",
    "y_pred_normal_flat = y_pred_normal.flatten()\n",
    "is_missing_normal_flat = is_missing_normal.flatten()\n",
    "valid_mask_normal = ~is_missing_normal_flat\n",
    "\n",
    "y_true_normal_unscaled = inverse_transform(y_true_normal, scaler).flatten()\n",
    "y_pred_normal_unscaled = inverse_transform(y_pred_normal, scaler).flatten()\n",
    "y_true_normal_valid = y_true_normal_unscaled[valid_mask_normal]\n",
    "y_pred_normal_valid = y_pred_normal_unscaled[valid_mask_normal]\n",
    "\n",
    "mae_normal = mean_absolute_error(y_true_normal_valid, y_pred_normal_valid)\n",
    "rmse_normal = np.sqrt(mean_squared_error(y_true_normal_valid, y_pred_normal_valid))\n",
    "nonzero_normal = y_true_normal_valid != 0\n",
    "mape_normal = np.mean(np.abs(\n",
    "    (y_true_normal_valid[nonzero_normal] - y_pred_normal_valid[nonzero_normal]) / y_true_normal_valid[nonzero_normal]\n",
    ")) * 100 if nonzero_normal.any() else 0.0\n",
    "smape_normal = smape(y_true_normal_valid, y_pred_normal_valid)\n",
    "\n",
    "# === 결과 출력 ===\n",
    "print(\"=\" * 75)\n",
    "print(\"DCRNN Performance Comparison (Original Scale)\")\n",
    "print(\"=\" * 75)\n",
    "print(f\"\\n{'Metric':<10} {'All Sensors':>15} {'Highway':>15} {'Normal Road':>15}\")\n",
    "print(\"-\" * 75)\n",
    "print(f\"{'MAE':<10} {mae_all:>15.4f} {mae_unscaled:>15.4f} {mae_normal:>15.4f}\")\n",
    "print(f\"{'RMSE':<10} {rmse_all:>15.4f} {rmse_unscaled:>15.4f} {rmse_normal:>15.4f}\")\n",
    "print(f\"{'MAPE (%)':<10} {mape_all:>15.2f} {mape_unscaled:>15.2f} {mape_normal:>15.2f}\")\n",
    "print(f\"{'sMAPE (%)':<10} {smape_all:>15.2f} {smape_unscaled:>15.2f} {smape_normal:>15.2f}\")\n",
    "print(\"=\" * 75)\n",
    "\n",
    "print(f\"\\n=== Data Points Summary ===\")\n",
    "print(f\"All sensors valid points: {valid_mask_all.sum():,}\")\n",
    "print(f\"Highway valid points: {valid_mask.sum():,}\")\n",
    "print(f\"Normal road valid points: {valid_mask_normal.sum():,}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebooks-3.11 (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
