{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install geopandas\n",
    "%pip install matplotlib\n",
    "%pip install seaborn\n",
    "%pip install missingno\n",
    "%pip install scipy\n",
    "%pip install -e ../songdo_metr/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from typing import Dict, List\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from metr.components.metadata import Metadata\n",
    "from metr.components.metr_imc.traffic_data import TrafficData\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"AppleGothic\"\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False  # 음수 부호 깨짐 방지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"METR-LA\")\n",
    "roads_la: gpd.GeoDataFrame = gpd.read_file(\"../datasets/METRLA/miscellaneous/sensor_nodes.shp\")\n",
    "roads_la.explore(color=\"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PEMS-BAY\")\n",
    "roads_pems: gpd.GeoDataFrame = gpd.read_file(\"../datasets/PEMSBAY/miscellaneous/sensor_nodes.shp\")\n",
    "roads_pems.explore(color=\"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Incheon\")\n",
    "roads_imc: gpd.GeoDataFrame = gpd.read_file(\"../datasets/metr-imc/miscellaneous/sensor_nodes.shp\")\n",
    "roads_imc.explore(color=\"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_la = pd.read_hdf(\"../datasets/METRLA/metr-la.h5\")\n",
    "df_la.iloc[:, :7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pems = pd.read_hdf(\"../datasets/PEMSBAY/pems-bay.h5\")\n",
    "df_pems.iloc[:, :7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metr_imc = TrafficData.import_from_hdf(\"../datasets/metr-imc/metr-imc.h5\")\n",
    "df_imc = metr_imc.data\n",
    "df_imc.iloc[:, :7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metr_imc_meta = Metadata.import_from_hdf(\"../datasets/metr-imc/metadata.h5\")\n",
    "imc_metadata = metr_imc_meta.data\n",
    "imc_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Statistic Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptions of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Description of METR-LA\")\n",
    "print(df_la.reset_index(drop=True).melt()[\"value\"].describe().apply(lambda x: format(x, '.4f')))\n",
    "print(\"Missing values count:\", df_la.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Description of PEMS-BAY\")\n",
    "print(df_pems.reset_index(drop=True).melt()[\"value\"].describe().apply(lambda x: format(x, '.4f')))\n",
    "print(\"Missing values count:\", df_pems.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기본적으로 인천시 데이터는 결측치와 이상치를 포함하고 있다. 따라서 대부분의 인천시 데이터에서 결측치의 개수는 0보다 크고, 최대값은 매우 큰 값을 가진다.\n",
    "\n",
    "The Incheon dataset generally contains missing values and outliers. As a result, in most cases, the missing values count is greater than 0, and the max value is unusually large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Description of the Incheon dataset\")\n",
    "print(df_imc.reset_index(drop=True).melt()[\"value\"].describe().apply(lambda x: format(x, '.4f')))\n",
    "print(\"Missing values count:\", df_imc.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots by Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_by_time(df: pd.DataFrame, title: str):\n",
    "    groups = df.groupby([df.index.hour, df.index.minute, df.index.second])\n",
    "    mean_df = groups.apply(lambda x: x.stack().mean())\n",
    "\n",
    "    mean_df.index = [\n",
    "        datetime(year=1970, month=1, day=1, hour=h, minute=m, second=s)\n",
    "        for h, m, s in mean_df.index\n",
    "    ]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(x=mean_df.index, y=mean_df.values)\n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter(\"%H:%M:%S\"))\n",
    "\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Average Value\")\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_by_time(df_la, \"METR-LA\")\n",
    "plot_by_time(df_pems, \"PEMS-BAY\")\n",
    "plot_by_time(df_imc, \"Incheon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_by_days(df: pd.DataFrame, name: str):\n",
    "    data_list = []\n",
    "\n",
    "    for day in range(7):\n",
    "        day_data = df[df.index.dayofweek == day]\n",
    "        numeric_cols = day_data.select_dtypes(include=[np.number]).columns\n",
    "        day_numeric = day_data[numeric_cols]\n",
    "        values = day_numeric.values.flatten()\n",
    "        values = values[~np.isnan(values)]\n",
    "        df_day = pd.DataFrame({\"Speed\": values, \"Days\": day})\n",
    "        data_list.append(df_day)\n",
    "\n",
    "    df_all = pd.concat(data_list, ignore_index=True)\n",
    "\n",
    "    # 요일 레이블 매핑\n",
    "    day_labels = {0: \"Mon\", 1: \"Tue\", 2: \"Wed\", 3: \"Thu\", 4: \"Fri\", 5: \"Sat\", 6: \"Sun\"}\n",
    "    df_all[\"Days\"] = df_all[\"Days\"].map(day_labels)\n",
    "    df_all[\"Days\"] = pd.Categorical(\n",
    "        df_all[\"Days\"],\n",
    "        categories=[\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"],\n",
    "        ordered=True,\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(\n",
    "        x=\"Days\",\n",
    "        y=\"Speed\",\n",
    "        data=df_all,\n",
    "        order=[\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"],\n",
    "    )\n",
    "    plt.xlabel(\"Days\")\n",
    "    plt.ylabel(\"Speed\")\n",
    "    plt.title(f\"Data by Day in {name}\")\n",
    "    plt.grid(True)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    formatter = FuncFormatter(lambda x, pos: f'{int(x):,}')\n",
    "    ax.yaxis.set_major_formatter(formatter)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_by_days(df_la, \"METR-LA\")\n",
    "plot_by_days(df_pems, \"PEMS-BAY\")\n",
    "plot_by_days(df_imc, \"Incheon\")\n",
    "# Lots of outliers in Incheon "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(\n",
    "    df: pd.DataFrame,\n",
    "    name: str,\n",
    "    exclude_zero: bool = False,\n",
    "    y_max: float = None,\n",
    "    x_max: float = None,\n",
    "    bins: int = 50,\n",
    "):\n",
    "    values = df.values.flatten()\n",
    "    values = values[~np.isnan(values)]\n",
    "\n",
    "    if exclude_zero:\n",
    "        values = values[values != 0]\n",
    "\n",
    "    if x_max is not None:\n",
    "        bin_edges = np.histogram_bin_edges(\n",
    "            values, bins=bins, range=(values.min(), x_max)\n",
    "        )\n",
    "        bin_edges = np.append(bin_edges, np.inf)\n",
    "    else:\n",
    "        bin_edges = bins\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(values, bins=bin_edges, kde=True)\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.title(f\"Histogram of {name}\")\n",
    "    plt.grid(True)\n",
    "\n",
    "    if y_max is not None:\n",
    "        plt.ylim(top=y_max)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    formatter = FuncFormatter(lambda x, _: f\"{int(x):,}\")\n",
    "    ax.yaxis.set_major_formatter(formatter)\n",
    "    ax.xaxis.set_major_formatter(formatter)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(df_la, \"METR-LA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(df_pems, \"PEMS-BAY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인천시 데이터의 경우 일반적인 한 방향의 도로에서 8000이상의 교통량은 불가능하다. 이에 따라 8000까지만 제한하여 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(df_imc, \"Incheon\", y_max=2000000, x_max=2000)\n",
    "plot_hist(df_imc, \"Incheon\", y_max=100000, x_max=8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspection of Time-Series Data Structure and Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-- METR-LA\\n\", f\"dtype: {df_la.index.dtype}\\n\", f\"length: {len(df_la.index)}\", end=\"\\n\\n\")\n",
    "print(\"-- PEMS-BAY\\n\", f\"dtype: {df_pems.index.dtype}\\n\", f\"length: {len(df_pems.index)}\", end=\"\\n\\n\")\n",
    "print(\"-- Incheon\\n\", f\"dtype: {df_imc.index.dtype}\\n\", f\"length: {len(df_imc.index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"METR-LA\")\n",
    "print(\"Is time series index:\", isinstance(df_la.index, pd.DatetimeIndex))\n",
    "print(\"Monotonic Increase:\", df_la.index.is_monotonic_increasing)\n",
    "print(\"Time Freq:\", pd.infer_freq(df_la.index))\n",
    "print()\n",
    "\n",
    "print(\"PEMS-BAY\")\n",
    "print(\"Is time series index:\", isinstance(df_pems.index, pd.DatetimeIndex))\n",
    "print(\"Monotonic Increase:\", df_pems.index.is_monotonic_increasing)\n",
    "print(\"Time Freq:\", pd.infer_freq(df_pems.index))\n",
    "print()\n",
    "\n",
    "print(\"Incheon\")\n",
    "print(\"Is time series index:\", isinstance(df_imc.index, pd.DatetimeIndex))\n",
    "print(\"Monotonic Increase:\", df_imc.index.is_monotonic_increasing)\n",
    "print(\"Time Freq:\", pd.infer_freq(df_imc.index))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"METR-LA\")\n",
    "time_diffs = df_la.index.to_series().diff()\n",
    "time_diffs = time_diffs[1:]\n",
    "gaps = time_diffs[time_diffs != pd.Timedelta(minutes=5)]\n",
    "\n",
    "if gaps.empty:\n",
    "    print(\"Index is 5-minutes interval\")\n",
    "else:\n",
    "    print(\"Index is not 5-minutes interval\")\n",
    "    for idx in gaps.index:\n",
    "        print(f\"From: {df_la.index[df_la.index.get_loc(idx) - 1]}, To: {idx}\")\n",
    "\n",
    "print(\"\\r\\nPEMS-BAY\")\n",
    "time_diffs = df_pems.index.to_series().diff()\n",
    "time_diffs = time_diffs[1:]\n",
    "gaps = time_diffs[time_diffs != pd.Timedelta(minutes=5)]\n",
    "\n",
    "if gaps.empty:\n",
    "    print(\"Index is 5-minutes interval\")\n",
    "else:\n",
    "    print(\"Index is not 5-minutes interval\")\n",
    "    for idx in gaps.index:\n",
    "        print(f\"From: {df_pems.index[df_pems.index.get_loc(idx) - 1]}, To: {idx}\")\n",
    "\n",
    "print(\"\\r\\nIncheon\")\n",
    "time_diffs = df_imc.index.to_series().diff()\n",
    "time_diffs = time_diffs[1:]\n",
    "gaps = time_diffs[time_diffs != pd.Timedelta(hours=1)]\n",
    "\n",
    "if gaps.empty:\n",
    "    print(\"Index is 1-hour interval\")\n",
    "else:\n",
    "    print(\"Index is not 1-hour interval\")\n",
    "    for idx in gaps.index:\n",
    "        print(f\"From: {df_imc.index[df_imc.index.get_loc(idx) - 1]}, To: {idx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-- METR-LA\\n\", f\"dtype: {df_la.dtypes.unique().tolist()}\\n\", f\"length: {len(df_la.columns)}\", end=\"\\n\\n\")\n",
    "print(\"-- PEMS-BAY\\n\", f\"dtype: {df_pems.dtypes.unique().tolist()}\\n\", f\"length: {len(df_pems.columns)}\", end=\"\\n\\n\")\n",
    "print(\"-- Incheon\\n\", f\"dtype: {df_la.dtypes.unique().tolist()}\\n\", f\"length: {len(df_imc.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers in Incheon Data\n",
    "\n",
    "앞서 살펴본 바에 따르면, 인천 데이터에는 다른 데이터에서는 볼 수 없는 Outlier가 많이 존재하며 비정상적인 값들이 많다. 이를 처리할 수 있는 방법이 필요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hourly_data(df: pd.DataFrame, col_idx: int):\n",
    "    series = df.iloc[:, col_idx]\n",
    "    groups = series.groupby(\n",
    "        [\n",
    "            series.index.hour,\n",
    "            series.index.minute,\n",
    "            series.index.second,\n",
    "        ]\n",
    "    )\n",
    "    data = groups.apply(lambda x: x.reset_index(drop=True)).reset_index()\n",
    "\n",
    "    data[\"Time\"] = data[\"level_0\"]\n",
    "    col_name = df.columns[col_idx]\n",
    "    data = data[[\"Time\", col_name]]\n",
    "\n",
    "    # 열 이름 변경\n",
    "    data.columns = [\"Time\", \"Value\"]\n",
    "\n",
    "    return data, col_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_iqr_outliers(df: pd.DataFrame, col_idx: int = 0):\n",
    "    data, col_name = get_hourly_data(df, col_idx)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.boxplot(x=\"Time\", y=\"Value\", data=data)\n",
    "    plt.title(f\"Outliers in {col_name}\")\n",
    "    plt.show()\n",
    "\n",
    "    return col_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_zscore_outliers(df: pd.DataFrame, col_idx: int = 0, z_threshold: float = 3.5):\n",
    "    data, col_name = get_hourly_data(df, col_idx)\n",
    "    \n",
    "    error_band = []\n",
    "    for hour in range(24):\n",
    "        series = data[data[\"Time\"] == hour][\"Value\"]\n",
    "        mean = series.mean()\n",
    "        std = series.std()\n",
    "        \n",
    "        lower_bound = mean - z_threshold * std\n",
    "        upper_bound = mean + z_threshold * std\n",
    "        error_band.append({\"Time\": hour, \"Mean\": mean, \"Lower\": lower_bound, \"Upper\": upper_bound})\n",
    "    \n",
    "    error_band = pd.DataFrame(error_band)\n",
    "\n",
    "    outlier_data = []\n",
    "    for hour in range(24):\n",
    "        series = data[data[\"Time\"] == hour][\"Value\"]\n",
    "        z_scores = stats.zscore(series, nan_policy=\"omit\")\n",
    "        outliers = series[np.abs(z_scores) > z_threshold]\n",
    "        for value in outliers:\n",
    "            outlier_data.append({\"Time\": hour, \"Value\": value})\n",
    "    \n",
    "    outlier_data = pd.DataFrame(outlier_data)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    sns.lineplot(x=\"Time\", y=\"Value\", data=data, label=\"Average Value\")\n",
    "    plt.fill_between(\n",
    "        error_band[\"Time\"],\n",
    "        error_band[\"Lower\"],\n",
    "        error_band[\"Upper\"],\n",
    "        color=\"gray\",\n",
    "        alpha=0.3,\n",
    "        label=f\"Z-Score Range ±{z_threshold}\"\n",
    "    )\n",
    "    \n",
    "    if not outlier_data.empty:\n",
    "        sns.scatterplot(x=\"Time\", y=\"Value\", data=outlier_data, color=\"red\", label=\"Outliers\")\n",
    "    \n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(col_name)\n",
    "    plt.title(f\"Z-Score ±{z_threshold} Range for {col_name}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return outlier_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_score_threshold = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = plot_iqr_outliers(df_imc, idx)\n",
    "plot_zscore_outliers(df_imc, idx, z_threshold=z_score_threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier 처리\n",
    "\n",
    "이상적인 차선 하나 당 이론적 최대 통행량은 다음과 같다.\n",
    "\n",
    "1. 제한속도 100km/h: 2200대\n",
    "3. 제한속도 80km/h: 2000대\n",
    "5. 제한속도 60km/h: 1800대\n",
    "\n",
    "즉, 10km/h 줄어들때마다 100대씩 줄어든다. 이를 기준으로 다시 분석한다.\n",
    "\n",
    "참조:\n",
    "오영태, 김수희, 정성환, & 함태식. (2008). 국내ㆍ외 고속도로 용량산정방법 비교ㆍ분석 연구. 한국 ITS 학회 학술대회, 29-36."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 제한속도 별 도로 분류 및 통행량 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_speed_map = imc_metadata.set_index(\"LINK_ID\")[\"MAX_SPD\"].to_dict()\n",
    "\n",
    "grouped_columns: Dict[int, List[str]] = {}\n",
    "for col in df_imc.columns:\n",
    "    if col in max_speed_map:\n",
    "        max_speed = max_speed_map[col]\n",
    "        if max_speed not in grouped_columns:\n",
    "            grouped_columns[max_speed] = []\n",
    "        grouped_columns[max_speed].append(col)\n",
    "\n",
    "grouped_df_imc = {speed: df_imc[cols] for speed, cols in grouped_columns.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_limit_list = sorted(grouped_df_imc.keys())\n",
    "speed_limit_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ideal_road_max_flow(speed: int, lanes_count: int = 1, rate: float = 1):\n",
    "    return (2200 - 10 * (100 - speed)) * lanes_count * rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_maxes = {100: 25000, 80: 10000, 70: 50000, 60: 600000, 50: 1000000, 40: 400000, 30: 200000}\n",
    "for speed in speed_limit_list:\n",
    "    x_max = get_ideal_road_max_flow(speed)\n",
    "    plot_hist(grouped_df_imc[speed], f\"Incheon Speed {speed}\", y_max=y_maxes[speed], x_max=x_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for speed in speed_limit_list:\n",
    "    plot_by_time(grouped_df_imc[speed], f\"Incheon Data at Max Speed {speed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 제한속도 별 이상치 있는 센서 시각화\n",
    "\n",
    "명백한 이상치가 있는 센서의 데이터를 시각화하고 어떤 문제가 있는지 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_speed_map = imc_metadata.set_index(\"LINK_ID\")[\"MAX_SPD\"].to_dict()\n",
    "lane_map = imc_metadata.set_index(\"LINK_ID\")[\"LANES\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_score_threshold = 5\n",
    "# [30, 40, 50, 60, 70, 80, 100]\n",
    "# target_max_speed = 50\n",
    "idx = 0\n",
    "rate = 1\n",
    "\n",
    "# ----- #\n",
    "\n",
    "prev_idx = idx\n",
    "prev_sensor = \"None\"\n",
    "\n",
    "# 최대속도로 최대 Lane 당 허용용량 설정\n",
    "# Lane 수로 도로의 허용용량 설정\n",
    "# 기준을 이 두개로 설정해서 다시 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_imc\n",
    "threshold = z_score_threshold\n",
    "\n",
    "\n",
    "def plot_sensor_data(\n",
    "    target_sensor_data: pd.Series,\n",
    "    expected_road_max: float,\n",
    "    title: str,\n",
    "):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # 전체 데이터 시각화\n",
    "    sns.lineplot(x=target_sensor_data.index, y=target_sensor_data.values)\n",
    "    plt.axhline(\n",
    "        y=expected_road_max,\n",
    "        color=\"red\",\n",
    "        linestyle=\"--\",\n",
    "        label=f\"Ideal Road Max: {expected_road_max}\",\n",
    "    )\n",
    "\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Average Value\")\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # z-score 이상치 시각화\n",
    "    outliers = plot_zscore_outliers(df, idx, z_threshold=threshold)\n",
    "    print(\"Missings:\", target_sensor_data.isna().sum())\n",
    "    print(\"Outliers:\", len(outliers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    if idx >= df_imc.shape[1]:\n",
    "        print(\"End of the sensors\")\n",
    "        break\n",
    "\n",
    "    target_sensor_data = df_imc.iloc[:, idx]\n",
    "    values = target_sensor_data.values.flatten()\n",
    "    values = values[~np.isnan(values)]\n",
    "\n",
    "    max_speed = max_speed_map[target_sensor_data.name]\n",
    "    lanes_count = lane_map[target_sensor_data.name]\n",
    "    expected_road_max = get_ideal_road_max_flow(max_speed, lanes_count, rate=rate)\n",
    "\n",
    "    exceed_count = (values > expected_road_max).sum()\n",
    "    if exceed_count > 0:\n",
    "        print(\n",
    "            f\"Previous Sensor({prev_idx}: {prev_sensor}) => Current Sensor({idx}: {target_sensor_data.name})\"\n",
    "        )\n",
    "        print()\n",
    "        non_missing_rate = (len(values) / len(target_sensor_data)) * 100\n",
    "        print(\n",
    "            f\"Data Counts: {len(values)} / {len(target_sensor_data)} ({non_missing_rate:.2f}%, Missing Rate: {100 - non_missing_rate:.2f}%)\"\n",
    "        )\n",
    "        print(f\"Max Speed: {max_speed} km/h\")\n",
    "        print(f\"Lanes: {lanes_count}\")\n",
    "        print(\n",
    "            f\"Ideal Flow Max: {get_ideal_road_max_flow(max_speed)} * {lanes_count} * {rate} = {expected_road_max}\"\n",
    "        )\n",
    "        print(f\"Exceed Count: {exceed_count}\")\n",
    "\n",
    "        sensor_map = plot_sensor_data(\n",
    "            target_sensor_data,\n",
    "            expected_road_max,\n",
    "            f\"Incheon Sensor {target_sensor_data.name}\",\n",
    "        )\n",
    "\n",
    "        prev_idx = idx\n",
    "        prev_sensor = target_sensor_data.name\n",
    "        idx += 1\n",
    "        break\n",
    "\n",
    "    idx += 1\n",
    "\n",
    "# 도로 위치 시각화\n",
    "target_sensor_position: gpd.GeoDataFrame = roads_imc[\n",
    "    roads_imc[\"LINK_ID\"] == target_sensor_data.name\n",
    "]\n",
    "target_sensor_position.explore(\n",
    "    color=\"blue\",\n",
    "    style_kwds={\"style_function\": lambda _: {\"radius\": 10}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_names_korean = [\n",
    "    \"1월\",\n",
    "    \"2월\",\n",
    "    \"3월\",\n",
    "    \"4월\",\n",
    "    \"5월\",\n",
    "    \"6월\",\n",
    "    \"7월\",\n",
    "    \"8월\",\n",
    "    \"9월\",\n",
    "    \"10월\",\n",
    "    \"11월\",\n",
    "    \"12월\",\n",
    "]\n",
    "months = sorted(target_sensor_data.index.month.unique())\n",
    "\n",
    "for month in months:\n",
    "    month_data = target_sensor_data[target_sensor_data.index.month == month]\n",
    "    month_name = month_names_korean[month - 1]\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.lineplot(x=month_data.index, y=month_data.values)\n",
    "    plt.axhline(\n",
    "        y=expected_road_max,\n",
    "        color=\"red\",\n",
    "        linestyle=\"--\",\n",
    "        label=f\"Ideal Road Max: {expected_road_max}\",\n",
    "    )\n",
    "\n",
    "    plt.xlabel(\"시간\")\n",
    "    plt.title(\n",
    "        f\"{target_sensor_data.name} - {month_name} Max(Speed: {max_speed} km/h, Flow: <{expected_road_max})\"\n",
    "    )\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outlier 기준은 다음과 같다.\n",
    "\n",
    "1. 10000 이상의 값은 비정상으로 인식\n",
    "2. z-score 5 이상은 비정상으로 인식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metr.components.metr_imc.outlier import AbsoluteOutlierProcessor, HourlyInSensorOutlierProcessor\n",
    "\n",
    "outlier_proc_1 = AbsoluteOutlierProcessor(threshold=10000)\n",
    "outlier_proc_2 = HourlyInSensorOutlierProcessor(threshold=z_score_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metr_imc.reset_data()\n",
    "metr_imc.remove_outliers([outlier_proc_1, outlier_proc_2])\n",
    "df_imc_outliers_removed = metr_imc.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_iqr_outliers(df_imc_outliers_removed, idx)\n",
    "plot_zscore_outliers(df_imc_outliers_removed, idx, z_threshold=z_score_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_name = col_name\n",
    "print(df_imc[sensor_name][df_imc[sensor_name] > 10000])\n",
    "print(\"IMC:\", df_imc[sensor_name].count())\n",
    "print(\"IMC_NoOut:\", df_imc_outliers_removed[sensor_name].count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Data in Incheon Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_columns_by_missing_range(df: pd.DataFrame):\n",
    "    total_cols = len(df.columns)\n",
    "    no_missing = len(df.columns[df.isnull().sum() == 0])\n",
    "    missing_1_to_100 = len(df.columns[(df.isnull().sum() > 0) & (df.isnull().sum() <= 100)])\n",
    "    missing_101_to_500 = len(df.columns[(df.isnull().sum() > 100) & (df.isnull().sum() <= 500)])\n",
    "    missing_501_to_750 = len(df.columns[(df.isnull().sum() > 500) & (df.isnull().sum() <= 750)])\n",
    "    missing_751_above = len(df.columns[df.isnull().sum() > 750])\n",
    "\n",
    "    print(f\"   Total Columns: {total_cols}\")\n",
    "    print(f\"   No Missing: {no_missing}\")\n",
    "    print(f\"   1 to 100 Missing: {missing_1_to_100}\")\n",
    "    print(f\"   101 to 500 Missing: {missing_101_to_500}\")\n",
    "    print(f\"   501 to 750 Missing: {missing_501_to_750}\")\n",
    "    print(f\"   751 or more Missing: {missing_751_above}\")\n",
    "\n",
    "# METR-LA\n",
    "print(\"-- METR-LA\")\n",
    "count_columns_by_missing_range(df_la)\n",
    "print()\n",
    "\n",
    "# PEMS-BAY\n",
    "print(\"-- PEMS-BAY\")\n",
    "count_columns_by_missing_range(df_pems)\n",
    "print()\n",
    "\n",
    "# Incheon\n",
    "print(\"-- Incheon\")\n",
    "count_columns_by_missing_range(df_imc)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_missingno(df: pd.DataFrame):\n",
    "    msno.matrix(df)\n",
    "    plt.show()\n",
    "\n",
    "    msno.heatmap(df, labels=False)\n",
    "    plt.show()\n",
    "\n",
    "    msno.bar(df)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_imc_outliers_removed[df_imc_outliers_removed.isnull().sum(axis=1) > 500]\n",
    "df_temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_missingno(df_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "missingno는 결측값 시각화 패키지이며 각 함수는 다음의 의미와 같다.\n",
    "1. matrix: 빈 공간은 결측값을 나타내며 이를 통해 결측 패턴을 파악.\n",
    "2. heatmap: 열 간 결측값 상관 계수를 히트맵으로 표시. 변수 간 결측값의 연관성 파악.\n",
    "3. bar: 결측값 갯수를 막대로 표시. 각 열(변수)의 결측값 갯수 파악."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 0.1\n",
    "\n",
    "data_columns = df_imc_sorted.columns\n",
    "num_columns_to_select = int(len(data_columns) * sample_rate)\n",
    "selected_columns = np.random.choice(data_columns, num_columns_to_select, replace=False)\n",
    "sampled_df = df_imc_sorted[selected_columns]\n",
    "\n",
    "print(f\"샘플링된 데이터 프레임의 크기: {sampled_df.shape}\")\n",
    "visualize_missingno(sampled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix에서 특정 날짜에서 결측값이 많아지는 경향을 볼 수 있다. 특히 데이터 시작 부분의 일정 기간 동안 결측값이 많이 관찰되었다. 특정 날짜에서 대부분의 센서들이 동작하지 않았을 가능성이 높다. 또한, 데이터 시작 부분의 데이터는 제외하는 것을 고려할 수 있다.\n",
    "\n",
    "Heatmap 분석에서는 결측값의 상관관계가 높은 경우가 많이 확인되었다. 일반적으로 이 경우 결측값 형태가 MAR(Missing At Random)이라고 판단한다. 다만 각 열이 모두 독립적인 센서임을 감안할 때, 각 센서가 영향을 주었을 가능성은 낮고 중앙 시스템에서 문제가 됬을 가능성이 높기 때문에 이 점을 감안할 필요가 있다.\n",
    "\n",
    "Bar 분석에서는 대부분 결측치가 많다는 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_traffic_data = df_imc[df_imc.columns[df_imc.isnull().sum() == 0][0]]\n",
    "\n",
    "plt.figure(figsize=(12, 2))\n",
    "sns.lineplot(sample_traffic_data)\n",
    "plt.title(f\"{sample_traffic_data.name} Road Traffic Data\")\n",
    "plt.xlabel(\"Date Time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최종적으로는 결측값을 포함한 전체 데이터셋을 기반으로 모델을 생성하고 성능을 평가해야 하지만 결측값 문제는 현재 집중하고 있는 연구 방향과는 독립적인 문제로 판단된다. 또한, 모든 데이터를 포함하면 데이터의 크기가 커져 학습 시간이 길어지는 문제도 있다. 따라서 현재는 데이터를 줄여 효율성을 높이고자 먼저 결측값이 없는 데이터를 사용하여 모델을 생성하고, 이 모델이 유효한지 판단한 후, 결측값 문제를 추가로 해결하는 방향으로 연구를 진행하고자 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_missing_columns = df_imc.columns[df_imc.isnull().sum() == 0].to_list()\n",
    "less_500_missing_columns = df_imc.columns[df_imc.isnull().sum() < 500].to_list()\n",
    "less_750_missing_columns = df_imc.columns[df_imc.isnull().sum() < 750].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from songdo_metr.dataset.metr_imc.converter.graph_sensor_locations import SensorView\n",
    "\n",
    "if not os.path.exists(\"../datasets/metr-imc/miscellaneous/no_missing.shp\"):\n",
    "    view = SensorView(\"../datasets/metr-imc/graph_sensor_locations.csv\")\n",
    "    view.set_filter(no_missing_columns)\n",
    "    view.export_to_file(\"../datasets/metr-imc/miscellaneous\", \"no_missing.shp\")\n",
    "    view.set_filter(less_500_missing_columns)\n",
    "    view.export_to_file(\"../datasets/metr-imc/miscellaneous\", \"missing_500.shp\")\n",
    "    view.set_filter(less_750_missing_columns)\n",
    "    view.export_to_file(\"../datasets/metr-imc/miscellaneous\", \"missing_750.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측치가 없는 데이터를 사용하는 것이 가장 이상적이지만, 이 경우 노드의 수가 너무 줄어들어 공간 정보가 모델에 충분히 반영되지 않을 가능성이 있다. 따라서, 기존에 많이 사용하는 METR-LA, PEMS-BAY 등의 데이터셋 크기와 유사한 수준으로 조정하였다. 결측치 허용 기준을 여러 개 비교한 결과, 500 정도가 기존 데이터셋과 유사한 크기를 유지하면서도 공간 정보를 적절히 반영할 수 있을 것으로 예상되었다.\n",
    "\n",
    "- 결측치가 하나도 없는 센서 노드\n",
    "\n",
    "![Missing_0](../docs/Missing_0.png)\n",
    "\n",
    "- 결측치 500개 미만의 센서 노드\n",
    "\n",
    "![Missing_500](../docs/Missing_500.png)\n",
    "\n",
    "- 결측치 750개 미만의 센서 노드\n",
    "\n",
    "![Missing_750](../docs/Missing_750.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이에 따라 500개 미만의 결측치를 가진 센서 노드만 별도로 추출하여 데이터셋을 다시 생성하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from songdo_traffic_core.dataset.metr_imc.generator import MetrImcSubsetGenerator\n",
    "\n",
    "generator = MetrImcSubsetGenerator(\n",
    "    nodelink_dir=\"../datasets/metr-imc/nodelink\",\n",
    "    imcrts_dir=\"../datasets/metr-imc/imcrts\",\n",
    "    metr_imc_dir=\"../datasets/metr-imc/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l500_missing_df, l500_columns = generator.process_metr_imc(less_500_missing_columns)\n",
    "l500_missing_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_missingno(l500_missing_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 그래프의 경우 원래데이터와 다르게 결측치 분포의 편차는 많이 제거되었다. 특정 기간동안 보이던 결측치 또한 많이 제거되어 있음을 확인할 수 있다. 센서마다 보이던 결측치의 상관관계도 많이 줄어들었다. 그러나 여전히 상관관계가 있는 결측치들이 있으며 이것은 여전히 결측치가 MAR임을 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "missing_patterns = l500_missing_df.isnull().astype(int)\n",
    "kmeans = KMeans(n_clusters=8, random_state=42)\n",
    "clusters = kmeans.fit_predict(missing_patterns.T)\n",
    "clustered_df = pd.DataFrame({'sensor': missing_patterns.columns, 'cluster': clusters})\n",
    "for cluster in set(clusters):\n",
    "    print(f\"Cluster {cluster}: {clustered_df[clustered_df['cluster'] == cluster]['sensor'].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_clusters = True\n",
    "\n",
    "if visualize_clusters:\n",
    "    for cluster in set(clusters):\n",
    "        cluster_sensors = clustered_df[clustered_df['cluster'] == cluster]['sensor'].tolist()\n",
    "        print(\"=\"*10, \"Cluster\", cluster, \"=\"*10)\n",
    "        plt.figure(figsize=(6, 2))\n",
    "        msno.matrix(l500_missing_df[cluster_sensors])\n",
    "        plt.title(f'Matrix Plot for Cluster {cluster}')\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(6, 2))\n",
    "        msno.heatmap(l500_missing_df[cluster_sensors], labels=False)\n",
    "        plt.title(f'Heatmap Plot for Cluster {cluster}')\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
