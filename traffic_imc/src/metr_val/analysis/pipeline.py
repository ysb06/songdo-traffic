"""
Traffic Analysis Pipeline
í´ë˜ìŠ¤ ê¸°ë°˜ êµ¬ì¡°ë¡œ ë¦¬íŒ©í† ë§ëœ êµí†µ ë¶„ì„ íŒŒì´í”„ë¼ì¸
"""

import logging
from pathlib import Path
from typing import Any, Dict, Tuple, List

import pandas as pd
import plotly.graph_objects as go
import torch
from metr.datasets.rnn.datamodule import MultiSensorTrafficDataModule

from . import MODEL_OUTPUT_DIR
from .error_analysis import analyze_dataset_errors, save_error_analysis_results
from .prediction_comparison import analyze_predictions, analyze_predictions_from_file
from .utils import load_or_train_model, load_config

logger = logging.getLogger(__name__)


class TrafficAnalysisPipeline:
    """êµí†µ ì˜ˆì¸¡ ë¶„ì„ì„ ìœ„í•œ ë©”ì¸ íŒŒì´í”„ë¼ì¸ í´ë˜ìŠ¤"""

    def __init__(self, config_path: str = None):
        """
        íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”

        Args:
            config_path: ì„¤ì • íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: config.yaml)
        """
        # ì„¤ì • ë¡œë“œ
        self.config: Dict[str, Dict[str, Any]] = load_config(config_path)
        self.analysis_config = self.config["analysis"]

        # ê²½ë¡œ ì„¤ì •
        self.dataset_path = self.analysis_config["dataset_path"]
        self.output_dir = MODEL_OUTPUT_DIR / "analysis_results"

        # ì´ˆê¸°í™”í•  ì†ì„±ë“¤
        self.model = None
        self.data_module = None
        self.datasets = {}
        self.results: Dict[str, Tuple[go.Figure, Dict[str, pd.DataFrame], go.Figure, List, List]] = {}

        logger.info("TrafficAnalysisPipeline ì´ˆê¸°í™” ì™„ë£Œ")

    def setup_model_and_data(self):
        """ëª¨ë¸ê³¼ ë°ì´í„° ëª¨ë“ˆì„ ì„¤ì •í•©ë‹ˆë‹¤."""
        logger.info("ëª¨ë¸ ë¡œë”© ì‹œì‘...")
        self.model = load_or_train_model()
        self.model.eval()

        # ëª¨ë¸ ë””ë°”ì´ìŠ¤ í™•ì¸
        device = next(self.model.parameters()).device
        logger.info(f"ëª¨ë¸ ë””ë°”ì´ìŠ¤: {device}")

        # ë°ì´í„° ëª¨ë“ˆ ì´ˆê¸°í™”
        logger.info(f"ë°ì´í„° ë¡œë”© ì‹œì‘: {self.dataset_path}")
        self.data_module = MultiSensorTrafficDataModule(
            dataset_path=self.dataset_path,
            shuffle_training=self.analysis_config.get("shuffle_training", False),
            scale_method=self.analysis_config.get("scale_method"),
        )
        self.data_module.setup()

        # ë°ì´í„°ë¡œë” ìƒì„±
        self.datasets = {
            "training": self.data_module.train_dataloader(),
            "validation": self.data_module.val_dataloader(),
            "test": self.data_module.test_dataloader(),
        }

        logger.info("ëª¨ë¸ ë° ë°ì´í„° ì„¤ì • ì™„ë£Œ")

    def analyze_single_dataset(
        self, dataset_name: str, dataloader
    ) -> Tuple[go.Figure, Dict[str, pd.DataFrame], go.Figure, List, List]:
        """ë‹¨ì¼ ë°ì´í„°ì…‹ì— ëŒ€í•œ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

        Args:
            dataset_name: ë°ì´í„°ì…‹ ì´ë¦„
            dataloader: ë°ì´í„°ë¡œë”

        Returns:
            ë¶„ì„ ê²°ê³¼ íŠœí”Œ (ì˜ˆì¸¡ ê·¸ë˜í”„, ê²°ê³¼ ë°ì´í„°, ì—ëŸ¬ ê·¸ë˜í”„, ì„¼ì„œ ë©”íŠ¸ë¦­, ìƒìœ„ ì—ëŸ¬)
        """
        logger.info(f"{dataset_name.upper()} ë°ì´í„° ë¶„ì„ ì‹œì‘...")

        # ì €ì¥ ê²½ë¡œ ì„¤ì •
        save_path = f"./output/analysis/model/rnn/traffic_prediction_{dataset_name}"
        h5_path = Path(save_path).with_suffix(".h5")
        pkl_path = Path(save_path).with_suffix(".pkl")

        # ì €ì¥ëœ ê²°ê³¼ê°€ ìˆëŠ”ì§€ í™•ì¸
        if (
            h5_path.exists()
            and pkl_path.exists()
            and self.analysis_config.get("save_predictions", True)
        ):
            logger.info(f"ì €ì¥ëœ ê²°ê³¼ íŒŒì¼ ë°œê²¬: {save_path}")
            logger.info("ì˜ˆì¸¡ì„ ê±´ë„ˆë›°ê³  ì €ì¥ëœ ê²°ê³¼ ë¡œë“œ...")
            fig, result = analyze_predictions_from_file(save_path)
        else:
            logger.info("ìƒˆë¡œìš´ ì˜ˆì¸¡ ìˆ˜í–‰...")
            device = next(self.model.parameters()).device
            fig, result = analyze_predictions(
                dataloader,
                self.model,
                device,
                save_path=(
                    save_path
                    if self.analysis_config.get("save_predictions", True)
                    else None
                ),
            )

        # ì—ëŸ¬ ë¶„ì„ ìˆ˜í–‰
        logger.info(f"{dataset_name} ë°ì´í„°ì…‹ ì—ëŸ¬ ë¶„ì„ ìˆ˜í–‰...")
        sensor_metrics, top_errors, error_fig = analyze_dataset_errors(
            result, dataset_name
        )

        logger.info(f"{dataset_name} ë¶„ì„ ì™„ë£Œ")
        return fig, result, error_fig, sensor_metrics, top_errors

    def analyze_all_datasets(self):
        """ëª¨ë“  ë°ì´í„°ì…‹ì— ëŒ€í•œ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
        logger.info("ì „ì²´ ë°ì´í„°ì…‹ ë¶„ì„ ì‹œì‘...")

        for dataset_name, dataloader in self.datasets.items():
            analysis_result = self.analyze_single_dataset(dataset_name, dataloader)
            self.results[dataset_name] = analysis_result

        logger.info("ì „ì²´ ë°ì´í„°ì…‹ ë¶„ì„ ì™„ë£Œ")

    def save_results(self):
        """ë¶„ì„ ê²°ê³¼ë¥¼ ì €ì¥í•©ë‹ˆë‹¤."""
        logger.info("ê²°ê³¼ ì €ì¥ ì‹œì‘...")

        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        self.output_dir.mkdir(parents=True, exist_ok=True)

        plotly_config: Dict[str, Any] = self.analysis_config.get("plotly", {})

        # ê° ë°ì´í„°ì…‹ë³„ë¡œ ê²°ê³¼ ì €ì¥
        for dataset_name, (
            fig,
            result,
            error_fig,
            sensor_metrics,
            top_errors,
        ) in self.results.items():
            # ì˜ˆì¸¡ ë¹„êµ ê·¸ë˜í”„ ì €ì¥
            html_path = self.output_dir / f"traffic_prediction_{dataset_name}.html"
            fig.write_html(
                str(html_path),
                include_plotlyjs=plotly_config.get("include_plotlyjs", "cdn"),
                config={
                    "displayModeBar": plotly_config.get("display_mode_bar", True),
                    "responsive": plotly_config.get("responsive", True),
                },
            )
            logger.info(f"{dataset_name} ì˜ˆì¸¡ ê·¸ë˜í”„ ì €ì¥: {html_path}")

            # ì—ëŸ¬ ë¶„ì„ ê·¸ë˜í”„ ì €ì¥
            error_html_path = self.output_dir / f"error_analysis_{dataset_name}.html"
            error_fig.write_html(
                str(error_html_path),
                include_plotlyjs=plotly_config.get("include_plotlyjs", "cdn"),
                config={
                    "displayModeBar": plotly_config.get("display_mode_bar", True),
                    "responsive": plotly_config.get("responsive", True),
                },
            )
            logger.info(f"{dataset_name} ì—ëŸ¬ ë¶„ì„ ê·¸ë˜í”„ ì €ì¥: {error_html_path}")

            # CSV ê²°ê³¼ ì €ì¥
            save_error_analysis_results(
                sensor_metrics, top_errors, dataset_name, str(self.output_dir)
            )

        logger.info(f"ëª¨ë“  ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {self.output_dir}")

    def print_summary(self):
        """ë¶„ì„ ê²°ê³¼ ìš”ì•½ì„ ì¶œë ¥í•©ë‹ˆë‹¤."""
        logger.info("=== ë¶„ì„ ê²°ê³¼ ìš”ì•½ ===")
        logger.info("ì €ì¥ëœ íŒŒì¼ë“¤:")

        for dataset_name in self.datasets.keys():
            logger.info(
                f"- traffic_prediction_{dataset_name}.html: {dataset_name} ë°ì´í„° ì˜ˆì¸¡ ë¹„êµ ê·¸ë˜í”„"
            )
            logger.info(
                f"- error_analysis_{dataset_name}.html: {dataset_name} ë°ì´í„° ì—ëŸ¬ ë¶„ì„ ê·¸ë˜í”„"
            )
            logger.info(
                f"- error_metrics_{dataset_name}.csv: {dataset_name} ë°ì´í„° ì„¼ì„œë³„ ë©”íŠ¸ë¦­"
            )
            logger.info(
                f"- top_errors_{dataset_name}.csv: {dataset_name} ë°ì´í„° Top 10 ì—ëŸ¬ ì¼€ì´ìŠ¤"
            )

        logger.info("ğŸ“Š ì˜ˆì¸¡ ë¹„êµ ê·¸ë˜í”„ì—ì„œ:")
        logger.info("- ìƒë‹¨ ë“œë¡­ë‹¤ìš´ìœ¼ë¡œ ì„¼ì„œë¥¼ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
        logger.info("- í•˜ë‹¨ ìŠ¬ë¼ì´ë”ë¡œ ì›”ì„ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
        logger.info("- ë²”ë¡€ë¥¼ í´ë¦­í•˜ì—¬ ë¼ì¸ì„ ìˆ¨ê¸°ê±°ë‚˜ í‘œì‹œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")

        logger.info("ğŸ“ˆ ì—ëŸ¬ ë¶„ì„ ê·¸ë˜í”„ì—ì„œ:")
        logger.info("- ì„¼ì„œë³„ MAE ë¶„í¬ íˆìŠ¤í† ê·¸ë¨")
        logger.info("- RMSE vs MAE ì„¼ì„œë³„ ì„±ëŠ¥ ì‚°ì ë„")
        logger.info("- ê°€ì¥ í° ì—ëŸ¬ Top 10 ë°”ì°¨íŠ¸")
        logger.info("- MAPE vs RÂ² ìƒê´€ê´€ê³„ ë¶„ì„")

    def run_complete_analysis(self):
        """ì „ì²´ ë¶„ì„ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        logger.info("=== êµí†µ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹œì‘ ===")

        try:
            # 1. ëª¨ë¸ê³¼ ë°ì´í„° ì„¤ì •
            self.setup_model_and_data()

            # 2. ëª¨ë“  ë°ì´í„°ì…‹ ë¶„ì„
            self.analyze_all_datasets()

            # 3. ê²°ê³¼ ì €ì¥
            self.save_results()

            # 4. ê²°ê³¼ ìš”ì•½ ì¶œë ¥
            self.print_summary()

            logger.info("=== êµí†µ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ ===")

        except Exception as e:
            logger.error(f"ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            raise
