import logging
from pathlib import Path
from typing import Dict, Tuple

import pandas as pd
import plotly.graph_objects as go
import torch
from metr.datasets.rnn.datamodule import MultiSensorTrafficDataModule
from tqdm import tqdm

from . import MODEL_OUTPUT_DIR
from .error_analysis import analyze_dataset_errors, save_error_analysis_results
from .pipeline import TrafficAnalysisPipeline
from .prediction_comparison import analyze_predictions, analyze_predictions_from_file
from .utils import load_or_train_model

logging.basicConfig(
    format="%(asctime)s %(name)s [%(levelname)s] %(message)s",
    datefmt="%Y/%m/%d %H:%M:%S",
    level=logging.INFO,
)

# ìƒˆë¡œìš´ í´ë˜ìŠ¤ ê¸°ë°˜ íŒŒì´í”„ë¼ì¸ ì‚¬ìš©
if __name__ == "__main__":
    pipeline = TrafficAnalysisPipeline()
    pipeline.run_complete_analysis()
else:
    # ê¸°ì¡´ ì½”ë“œ (í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€)
    analysis_target_model = load_or_train_model()

    # ë°ì´í„° ê²½ë¡œ ì„¤ì •
    dataset_path = "./data/selected_small_v1/metr-imc.h5"
    print(f"ë°ì´í„° ê²½ë¡œ: {dataset_path}")

    # MultiSensorTrafficDataModule ì´ˆê¸°í™”
    print("MultiSensorTrafficDataModule ì´ˆê¸°í™” ì¤‘...")
    data_module = MultiSensorTrafficDataModule(
        dataset_path=dataset_path, shuffle_training=False, scale_method=None
    )
    data_module.setup()

    training_loader = data_module.train_dataloader()
    validation_loader = data_module.val_dataloader()
    test_loader = data_module.test_dataloader()

    # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •
    analysis_target_model.eval()

    # ëª¨ë¸ì˜ ë””ë°”ì´ìŠ¤ í™•ì¸
    device = next(analysis_target_model.parameters()).device
    print(f"ëª¨ë¸ ë””ë°”ì´ìŠ¤: {device}")

    # ê° ë°ì´í„°ì…‹ì— ëŒ€í•´ ì˜ˆì¸¡ ë° ë¶„ì„ ìˆ˜í–‰
    datasets = {
        "training": training_loader,
        "validation": validation_loader,
        "test": test_loader,
    }

    results: Dict[
        str, Tuple[go.Figure, Dict[str, pd.DataFrame], go.Figure, list, list]
    ] = {}

    for dataset_name, dataloader in datasets.items():
        print(f"\n{dataset_name.upper()} ë°ì´í„°ì— ëŒ€í•œ ë¶„ì„ ì¤‘...")

        # ì €ì¥ ê²½ë¡œ ì„¤ì •
        save_path = f"./output/analysis/model/rnn/traffic_prediction_{dataset_name}"

        # ì €ì¥ëœ íŒŒì¼ ì¡´ì¬ í™•ì¸
        h5_path = Path(save_path).with_suffix(".h5")
        pkl_path = Path(save_path).with_suffix(".pkl")

        if h5_path.exists() and pkl_path.exists():
            print(f"ì €ì¥ëœ ê²°ê³¼ íŒŒì¼ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤: {save_path}")
            print("ì˜ˆì¸¡ì„ ê±´ë„ˆë›°ê³  ì €ì¥ëœ ê²°ê³¼ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤...")

            # ì €ì¥ëœ íŒŒì¼ì—ì„œ ê²°ê³¼ ë¡œë“œ
            fig, result = analyze_predictions_from_file(save_path)
        else:
            print("ì €ì¥ëœ ê²°ê³¼ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤...")

            # prediction_comparison.pyì˜ analyze_predictions í•¨ìˆ˜ ì‚¬ìš©
            fig, result = analyze_predictions(
                dataloader,
                analysis_target_model,
                device,
                save_path=save_path,
            )

        # ê²°ê³¼ ì €ì¥
        results[dataset_name] = (fig, result)

        # ì—ëŸ¬ ë¶„ì„ ìˆ˜í–‰
        print(f"{dataset_name} ë°ì´í„°ì…‹ ì—ëŸ¬ ë¶„ì„ ìˆ˜í–‰ ì¤‘...")
        sensor_metrics, top_errors, error_fig = analyze_dataset_errors(
            result, dataset_name
        )

        # ì—ëŸ¬ ë¶„ì„ ê²°ê³¼ë„ ì €ì¥
        results[dataset_name] = (fig, result, error_fig, sensor_metrics, top_errors)

        print(f"{dataset_name} ë¶„ì„ ì™„ë£Œ!")

    # ê²°ê³¼ ì €ì¥
    print("\nê²°ê³¼ë¥¼ ì €ì¥í•˜ëŠ” ì¤‘...")

    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_dir = MODEL_OUTPUT_DIR / "analysis_results"
    output_dir.mkdir(parents=True, exist_ok=True)

    # ê° ë°ì´í„°ì…‹ë³„ë¡œ HTML íŒŒì¼ ì €ì¥
    for dataset_name, (
        fig,
        result,
        error_fig,
        sensor_metrics,
        top_errors,
    ) in results.items():
        # ì˜ˆì¸¡ ë¹„êµ ê·¸ë˜í”„ ì €ì¥
        html_path = output_dir / f"traffic_prediction_{dataset_name}.html"
        fig.write_html(
            str(html_path),
            include_plotlyjs="cdn",
            config={"displayModeBar": True, "responsive": True},
        )
        print(f"{dataset_name} ì¸í„°ë™í‹°ë¸Œ ê·¸ë˜í”„ ì €ì¥: {html_path}")

        # ì—ëŸ¬ ë¶„ì„ ê·¸ë˜í”„ ì €ì¥
        error_html_path = output_dir / f"error_analysis_{dataset_name}.html"
        error_fig.write_html(
            str(error_html_path),
            include_plotlyjs="cdn",
            config={"displayModeBar": True, "responsive": True},
        )
        print(f"{dataset_name} ì—ëŸ¬ ë¶„ì„ ê·¸ë˜í”„ ì €ì¥: {error_html_path}")

        # ì—ëŸ¬ ë¶„ì„ ê²°ê³¼ë¥¼ CSVë¡œ ì €ì¥
        save_error_analysis_results(
            sensor_metrics, top_errors, dataset_name, str(output_dir)
        )

    print(f"\nëª¨ë“  ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_dir}")
    print("ì €ì¥ëœ íŒŒì¼ë“¤:")
    for dataset_name in datasets.keys():
        print(
            f"- traffic_prediction_{dataset_name}.html: {dataset_name} ë°ì´í„° ì˜ˆì¸¡ ë¹„êµ ê·¸ë˜í”„"
        )
        print(
            f"- error_analysis_{dataset_name}.html: {dataset_name} ë°ì´í„° ì—ëŸ¬ ë¶„ì„ ê·¸ë˜í”„"
        )
        print(
            f"- error_metrics_{dataset_name}.csv: {dataset_name} ë°ì´í„° ì„¼ì„œë³„ ë©”íŠ¸ë¦­"
        )
        print(
            f"- top_errors_{dataset_name}.csv: {dataset_name} ë°ì´í„° Top 10 ì—ëŸ¬ ì¼€ì´ìŠ¤"
        )

    print("\nğŸ“Š ì˜ˆì¸¡ ë¹„êµ ê·¸ë˜í”„ì—ì„œ:")
    print("- ìƒë‹¨ ë“œë¡­ë‹¤ìš´ìœ¼ë¡œ ì„¼ì„œë¥¼ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
    print("- í•˜ë‹¨ ìŠ¬ë¼ì´ë”ë¡œ ì›”ì„ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
    print("- ë²”ë¡€ë¥¼ í´ë¦­í•˜ì—¬ ë¼ì¸ì„ ìˆ¨ê¸°ê±°ë‚˜ í‘œì‹œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")

    print("\nğŸ“ˆ ì—ëŸ¬ ë¶„ì„ ê·¸ë˜í”„ì—ì„œ:")
    print("- ì„¼ì„œë³„ MAE ë¶„í¬ íˆìŠ¤í† ê·¸ë¨")
    print("- RMSE vs MAE ì„¼ì„œë³„ ì„±ëŠ¥ ì‚°ì ë„")
    print("- ê°€ì¥ í° ì—ëŸ¬ Top 10 ë°”ì°¨íŠ¸")
    print("- MAPE vs RÂ² ìƒê´€ê´€ê³„ ë¶„ì„")
